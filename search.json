[{"id":0,"type":"post","title":"<b>#48</b>Visual Studio Debugger Annoyances","url":"/rival-fortress-update-48-visual-studio-debugger-annoyances/index.html","game":"rival-fortress","date":"Dec 12, 2016","gameName":"Rival Fortress","content":"I do most of my game development on Linux, and I’m very happy with GDB, but when I have to do some debugging on Windows, Visual Studio is my debugger of choice.\n\nIn this post I’ll lightly rant about some of the features (or lack thereof) of the Visual Studio 2015 debugger:\n\n\n  \n    Let me add notes to variables in the Watch window. I often need to watch raw memory locations casted to the appropriate type (i.e. (Entity*)0x10021F0) in order to keep an eye on variables that are out of scope of the current function but I know still exist.\nWithout notes I sometimes have the watch window full of hex addresses casted to the same type, but no idea which one is which.\nA typical use case is watching a stack variable when stepping into a function.\n\n    In GDB I don’t have this problem because I can easily scroll back and see the entire debugging session, and search through it with few keystrokes.\n  \n  \n    Let me highlight a memory range in the Memory window. Maybe by dragging to select bytes and right-clicking.\nThis would in order to easily find the memory location when juggling multiple memory windows or jumping around a lot. I don’t know about you, but I really think the Memory window should get more love.\n\n    In GDB I use the awesome gdb-dashboard to keep an eye on multiple memory blocks of arbitrary sizes, as well as the following define that dumps a memory address+length:\n  \n\n\ndefine xdd\n  dump binary memory /tmp/dump.bin $arg0 $arg0+$arg1\n  shell hexdump -C /tmp/dump.bin\nend\n\n\n  \n    Show me the string length when inspecting a string in the Text Visualizer! Please, just add a little text box with the string length.\n  \n  Let me see the byte representation of a string when viewing it in the Text Visualizer (similar to the Memory window).\n  Let me drag the value of a char[] as an address to a new cell just like I can with char*.\n  Show me the memory address of a byte when mousing over an octet in a Memory window.\n  Add the “Hexadecimal display” toggle in the contextual menu for other windows too, (e.g. in the disassembly window), not only in the watch/locals/autos windows.\n  Let me drag out of scope variable addresses to the Memory window (useful when stepping into a function and want to inspect outer scope stack variables that are still valid).\n\n\n","preview":"I do most of my game development on Linux, and I’m very happy with GDB, but when I have to do some debugging on Windows, Visual Studio is my debugger...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":1,"type":"post","title":"<b>#47</b>Logical vs Memory Structure Arrangement","url":"/rival-fortress-update-47-logical-vs-memory-structure-arrangement/index.html","game":"rival-fortress","date":"Dec 5, 2016","gameName":"Rival Fortress","content":"In a previous post I talked about how avoiding automatic structure padding can be beneficial for performance, because of the importance of cache locality in modern CPU architectures.\n\nToday I’ll talk about why I wish C or C++ would allow us to specify a logical arrangement for struct members in order to increase code readability.\n\nData structure alignment\n\nIf you specify a structure or class in C/C++, the compiler will arrange its members in memory in the same order as you specified them in the struct/class definition (ignoring for the sake of simplicity virtual table pointers added in C++).\n\nSo, for example, the following struct will have the member X come before Y in memory.\n\nstruct MyData\n{\n  char X; // 1 byte\n  int Y;  // 4 bytes\n};\n\nIn this case, the compiler will also insert 3 bytes of padding after X in order to keep Y aligned to a word boundary.\n\nWhen default arrangement sucks\n\nDefault structure arrangement can be problematic at times, especially when dealing with large structures.\n\nFor example, it is often much more readable to group fields together logically, but this can lead to memory memory wastage caused by padding, like in the following simple example:\n\nstruct ReadableButSuboptimal\n{\n  entity* Entities;\n  u16 EntityCount;\n\n  mesh* Meshes;\n  u8 MeshCount;\n\n  shader* Shaders;\n  u8 ShaderCount;\n\n  u32 Flags;\n};\n\nThis is a perfectly reasonable arrangement for a human: each pointer is followed by the count for the array.\n\nUnfortunately, it also wastes memory, because of the bytes of padding introduced by the compiler. An optimal, but less readable arrangement would be the following:\n\nstruct LessReadableButOptimal\n{\n  entity* Entities;\n  mesh* Meshes;\n  shader* Shaders;\n\n  u16 EntityCount;\n  u8 MeshCount;\n  u8 ShaderCount;\n\n  u32 Flags;\n};\n\nThis arrangement wastes no bytes in padding, but is, in my opinion, less readable than the previous.\n\nLogical arrangement as an option\n\nA better approach for cases like this where the order of members is not important would be to specify structure members logically, for example by decorating the structure like so:\n\nstruct InAnIdealWorld\n{\n  entity* Entities;\n  u16 EntityCount;\n\n  mesh* Meshes;\n  u8 MeshCount;\n\n  shader* Shaders;\n  u8 ShaderCount;\n\n  u32 Flags;\n} __attribute__((rearrange)); // NOTE: Made up attribute, doesn't actually exist\n\nThis would tell the compiler: “Hey, I don’t really care about the order in which the members of this struct are laid out, rearrange them at will”.\n\nObviously this shouldn’t be the default behavior as it would cause all sorts of bugs when dealing with structures that have to cross API boundaries between libraries, but it would be very useful for internal subsystems…\n\nI think ;)\n","preview":"In a previous post I talked about how avoiding automatic structure padding can be beneficial for performance, because of the importance of cache locality in modern CPU architectures. Today I’ll...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":2,"type":"post","title":"<b>#46</b>Single Instance Games On Windows With C/C++","url":"/rival-fortress-update-46-single-instance-games-on-windows-with-c-cpp/index.html","game":"rival-fortress","date":"Nov 28, 2016","gameName":"Rival Fortress","content":"This week, among other Windows related things, I added a constrain to allow only a single instance of Rival Fortress to be run. This comes for free for games on Steam or GOG Galaxy, but it is a consideration when you are also distributing your game through other means.\n\nThe naive approach\nA naive approach is to use some sort of lock file that gets written by the first instance to a known location and checked for existence by subsequent instances.\nThe problem is that if your application fails to do its cleanup, you are left in a broken state where the user cannot open your app, unless they manually delete your super secret lock file.\n\nI’ve seen this done quite a few times in other code bases and the amount of code required to handle all possible failure cases is cringe-worthy.\n\nThe lightweight approach\n\nA interesting approach is based on leveraging the shared sections of Portable Executables.\n\nShared sections are neat little feature that allow multiple instances of the same executable or DLL to have a shared address space.\n\nThis can be exploited for the following super-lightweight solution to single instance applications:\n\n#ifdef _MSC_VER\n#pragma comment(linker, \"/SECTION:.oneinst,RWS\")\n#pragma data_seg(\".oneinst\")\nint IntancesRunning = 0;\n#pragma data_seg()\n\n#else\n\n//NOTE: GCC\nint InstancesRunning __attribute__((section(\".oneinst\"), shared)) = 0;\n#endif\n\nint WinMain(...)\n{\n    if (InstancesRunning++ == 0)\n    {\n      // NOTE: Normal code path\n    }\n    else\n    {\n      // NOTE: Handle second instance running\n    }\n    return 0;\n}\n\nThis snippet creates the variable InstancesRunning in the section .oneinst (that I made up) and marks it as shared using the #pragma statement on MSVC (RWS: Readable Writable Shared) and the __attribute__ on GCC. (You can also specify the command directly to link.exe using: -section:.oneinst,RWS, just as the #pragma statement does).\n\nWhen the last instance of an application exists, the shared memory is unmapped and the InstanceRunning variable is “reset”.\n\nA downside to this approach is that it only works for exact instances of the executable, so if the user makes a copy of the executable, windows will not map the section in the same address space as the first one.\n\nYou can read more about this approach in the MSDN article How do I share data in my DLL with an application or with other DLLs?. It’s intended for DLLs, but works just as fine with normal executables.\n\nAlso, if you are writing an application with security concerns read Raymond Chen’s Why .shared sections are a security hole before using this approach to shuttle data back and forth between instances.\n\nThe best approach\nThe ideal approach is to use a named mutex using a call to CreateMutex during startup.\nThis works well and, to my knowledge, has no downsides.\n\nThis is how you would implement one:\n\nint WinMain(...)\n{\n    CreateMutexA(0, 1, \"Global\\\\MyGameMutex\");\n    if (GetLastError() != ERROR_ALREADY_EXISTS)\n    {\n      // NOTE: Normal code path\n    }\n    else\n    {\n      // NOTE: Handle second instance running\n    }\n    return 0;\n}\n\nA global named mutex is created by the first instance of your application, and cleaned up automatically by Windows when your application shuts down. If a second instance of the application starts, the call to GetLastError() will return ERROR_ALREADY_EXISTS, so you can check that.\n\n","preview":"This week, among other Windows related things, I added a constrain to allow only a single instance of Rival Fortress to be run. This comes for free for games on...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":3,"type":"post","title":"<b>#45</b>Dealing with __chkstk/__chkstk_ms when Cross-Compiling For Windows","url":"/rival-fortress-update-45-dealing-with-__chkstk-__chkstk_ms-when-cross-compiling-for-windows/index.html","game":"rival-fortress","date":"Nov 21, 2016","gameName":"Rival Fortress","content":"If you have a cross-compiling toolchain for building Windows executables read on.\n\nI use both Clang and Mingw-w64, and I’ve recently discovered a “fun” little gotcha that has to do with the __chkstk routine that is output automatically by the code generator of both compilers.\n\nWhat is __chkstk\n\nThe __chkstk routine (also known as __alloc_probe) is a little procedure that is inserted by compilers targeting Windows executables in the prologue code for each function that uses more that 4K bytes (8K in 64bit).\n\nBy default Windows allocates stack space in 4K pages with a guard page at the end that triggers an access violation when the program tries to access it, causing the operating system to allocate more stack space.\n\nA problem arises when a function uses more than 2 pages for its stack variables. This means that it could possibly access memory past the guard page, thus triggering an access violation that won’t be handled by the OS as a simple request for more stack space, but as a generic exception that would terminate the application.\n\n__chkstk is the solution to this problem. Upon function entry, it touches memory addresses every 4K from the current stack pointer location up to the size needed by the function. This triggers the guard pages in the proper sequence and commits additional memory to the stack as required.\n\n__chkstk can also speed up your application’s start up time, even though, for most indie games and even some triple A game, the speed up will be negligible.\n\nRead Compiler Security Checks In Depth for more details.\n\nWhy you may not want __chkstk\n\nAs you may imagine, having this little routine run on every function call is wasteful. The cost of each page fault is paid only once, but __chkstk has to do its little dance and burn cycles on instructions that do nothing every time a function is called.\n\nFortunately it can be disabled on MSVC with the following cl.exe flags:\n\n\n  /GsXXX where XXX is the threshold in bytes that prompts the insertion of the __chkstk probe. If you set this to a high number, like 10000000, no stack probes will be inserted.\n  /STACK:reserve[,commit] reserves and, more importantly, commits the specified bytes for stack space used by the application. By default reserve is 1 MB and commit is 4 KB, so if you set both reserve and commit to the same number you won’t have to manually trigger faults to expand stack space.\n\n\nLLVM and mingw don’t support __chkstk disabling\n\nUnfortunately LLVM’s code generator for Windows targets use an hard-coded probe size of 4K as of LLVM 5.0, and this size can only be changed on a per-function basis with the stack-probe-size function attribute.\n\nThe same goes for mingw-w64, as it automatically outputs the __chkstk_ms probe for functions that use more than 4 KB, and to my knowledge there is no way to change this, but I didn’t dig deep in the source, as I use mingw only for continuous integration, and not for my main builds.\n\nThe solution I went with is to just redefine the function __chkstk as a no-op in assembly like so:\n\n.text\n.global __chkstk\n__chkstk:\n  ret\n\nWhen I’ll get further along and lock all toolchain versions, I’ll modify the source to the Windows LLVM code generator to remove the call to __chkstk, but for now this is a quick and painless solution.\n\n","preview":"If you have a cross-compiling toolchain for building Windows executables read on. I use both Clang and Mingw-w64, and I’ve recently discovered a “fun” little gotcha that has to do...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":4,"type":"post","title":"<b>#44</b>Reducing The Platform API Surface","url":"/rival-fortress-update-44-reducing-the-platform-surface/index.html","game":"rival-fortress","date":"Nov 14, 2016","gameName":"Rival Fortress","content":"This week I started work on the Windows platform layer for Rival Fortress, and while I was at it, I also reduced the number of functions exposed by the API.\n\nThe platform layer\n\nAs is common in many modern games,  Rival Fortress doesn’t interact directly with the operating system, but make calls through a platform API that is a thin abstraction over OS services.\n\nFor example, the platform API exposes an AllocateMemory function that returns a chunk of memory, and behind the scenes uses a custom allocator for the OS based on VirtualAlloc on Windows or mmap on Linux/macOS.\n\nThe advantage of this approach is that it removes platform implementation details from game code and makes portability much easier: as long as the platform can expose all functions in the API, the game will run.\n\nYou may argue that the C/C++ standard library already provides this level of abstraction and portability, but having a tight API boundary gives you the flexibility of using whatever you want behind the scenes, like optimized system calls if standard library functions are not ideal.\n\nStriving for a minimal API\n\nDesigning the The platform API is tricky. The number of functions exposed needs to strike a balance between just enough to get the job done efficiently and not too many as to negate the usefulness of the idea.\n\nThe platform API for Rival Fortress has gone through many iterations, and in its current state it looks like this:\n\ntypedef struct MPEPlatformAPI\n{\n  // NOTE: Memory\n  PFN_AllocateMemory AllocateMemory;\n  PFN_DeallocateMemory DeallocateMemory;\n\n\n  // NOTE: Filesystem\n  PFN_GetDirectoryList GetDirectoryList;\n  PFN_FileOpen FileOpen;\n  PFN_FileClose FileClose;\n  PFN_FileRead FileRead;\n  PFN_FileWrite FileWrite;\n\n  // NOTE: Threading\n  PFN_SemaphorePost SemaphorePost;\n  PFN_SemaphoreWait SemaphoreWait;\n\n  // NOTE: I/O\n  PFN_PollEvents PollEvents;\n  PFN_SubmitGraphicsAndSound SubmitGraphicsAndSound;\n\n} MPEPlatformAPI;\n\nPFN_ is the prefix I use for typedef-ed function pointers.\n\nIn debug builds the game code is built as a DLL, so platform API is passed as a struct that is copied to a global object, so that the game code can be unloaded and reloaded as I explain in the Hot Swappable Game Modules post.\n\nIn release builds the game and platform are built as a single executable, so function pointers are not needed and the API functions are called directly.\n\nIn code, platform calls go through the MPE_PLATFORM macro, that conditionally calls the function pointers or the functions directly like so:\n\n#if MPE_BUILD_STANDALONE_EXE\n#define MPE_PLATFORM(Name, ...) MPE_Platform##Name(__VA_ARGS__)\n#else\nstatic MPEPlatformAPI GlobalPlatformAPI;\n#define MPE_PLATFORM(Name, ...) GlobalPlatformAPI.Name(__VA_ARGS__)\n#endif\n\n","preview":"This week I started work on the Windows platform layer for Rival Fortress, and while I was at it, I also reduced the number of functions exposed by the API....","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":5,"type":"post","title":"<b>#43</b>Standalone Assembly Files And Inlining","url":"/rival-fortress-update-43-standalone-assembly-files-and-inlining/index.html","game":"rival-fortress","date":"Nov 7, 2016","gameName":"Rival Fortress","content":"Every so often, when the compiler is slacking, I pop the hood and get my hands dirty with assembly.\n\nMy modus operandi is to write the optimized function in an .asm, assemble it with NASM and add it to the build, along with other .asm functions, as a static library.\n\nThe problem with this approach is that, to my knowledge, GCC, Clang and MSVC are not able to apply Link Time Optimization when working with object files that have been compiled from assembly.\n\nThis means that even simple procedures or functions are not inlined, and have to pay the overhead associated with a function call.\n\nA simple example\n\nIgnoring for a moment the fact that the every compiler exposes a builtin that provides this exact functionality (e.g. __builtin_ia32_rdtsc()), imagine you needed to add a Time Stamp Counter function to your application.\n\nThe following is a dummy application that uses the RDTSC function (the multiply between GetRDTSC and argc is there to avoid the compiler optimizing it away):\n\n#ifdef __cplusplus\nextern \"C\"\n#endif\nunsigned long GetRDTSC();\n\nint\nmain(int argc, char** argv)\n{\n  int Result = (int)(GetRDTSC() * argc);\n  return Result;\n}\n\nIn order to add the functionality you would have two approaches:\n\n\n  compile the function as a standalone assembly file and add the object file to your build\n  use inline assembly (if your compiler supports it)\n\n\nStandalone assembly\n\nStandalons assembly works on all compilers and, using AT&amp;T syntax, looks like this:\n\n.global GetRDTSC\n\nGetRDTSC:\n  rdtsc         // read time-stamp counter into EDX:EAX\n  shl $32, %rdx // combine into RAX register\n  or %rdx, %rax\n  ret\n\nThe output produced by GCC and Clang (MSVC produces something similar) when compiled with all optimizations (-O3 -flto) is:\n\n Dump of assembler code for function main:\n   0x00000000004004a0 &lt;+0&gt;:     push   %rbx\n   0x00000000004004a1 &lt;+1&gt;:     mov    %edi,%ebx\n   0x00000000004004a3 &lt;+3&gt;:     callq  0x400488 &lt;GetRDTSC&gt;\n   0x00000000004004a8 &lt;+8&gt;:     imul   %ebx,%eax\n   0x00000000004004ab &lt;+11&gt;:    pop    %rbx\n   0x00000000004004ac &lt;+12&gt;:    retq\n\nAs you can see, the function has not been inlined, despite begin just three instructions, because (I speculate) the assembler doesn’t decorate the object file with the metadata required by linker in order to optimize the function away when going through link time optimization.\n\nThe inline assembly way\n\nWhen using inline assembly, on the other hand, things work as expected, and the resulting binary is optimized correctly.\n\nThis is the inline equivalent of the previous GetRDTSC function, using the GCC Extended Asm syntax:\n\nstatic unsigned long\nGetRDTSC()\n{\n  // read time-stamp counter into EDX:EAX\n  // then combine into RAX register\n  unsigned Low, High;\n  __asm__(\"rdtsc\" : \"=a\"(Low), \"=d\" (High));\n  return ((unsigned long)Low) | (((unsigned long)High) &lt;&lt; 32);\n}\n\nAnd this is the disassembled main function:\n\n Dump of assembler code for function main:\n   0x00000000004003b0 &lt;+0&gt;:     rdtsc\n   0x00000000004003b2 &lt;+2&gt;:     shl    $0x20,%rdx\n   0x00000000004003b6 &lt;+6&gt;:     or     %rdx,%rax\n   0x00000000004003b9 &lt;+9&gt;:     imul   %edi,%eax\n   0x00000000004003bc &lt;+12&gt;:    retq\n\nPerfect! The function call and associated stack manipulation are gone, and only the essential instructions remain.\n\nThis is the superior approach for compact procedures that are invoked frequently, but can quickly become impossible to maintain as the complexity of the assembly function rises.\n\nIn Rival Fortress I use a mixture of both approaches: I initially write and debug assembly functions as standalone files, and during profiling sessions I decided if it is worth it to inline them.\n\nNOTE: Inline assembly doesn’t work on MSVC when compiling for x64 targets, so you are out of luck if that is your compiler of choice.\n","preview":"Every so often, when the compiler is slacking, I pop the hood and get my hands dirty with assembly. My modus operandi is to write the optimized function in an...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":6,"type":"post","title":"<b>#42</b>Code Cleanup","url":"/rival-fortress-update-42-code-cleanup/index.html","game":"rival-fortress","date":"Oct 31, 2016","gameName":"Rival Fortress","content":"After last week’s transition from C++ to C99, I decided to dedicate this week to code cleanup.\n\nRe-enabling all warnings\nMy compiler of choice is Clang and I like to build with the -Weverything and disabled warnings to a minimum, but whenever I do a cleanup pass (or when I upgrade my compiler toolchain) I re-enable all warnings in order to reassess the state of the codebase.\n\nI also try to keep the code GCC-compatible, but I usually only use it during cleanup/benchmarking sessions, as I find it to be slower than Clang for day-to-day usage. Plus I feel the warnings are still not up to par, compared with Clang’s excellent error reporting.\n\nMerciless removal, courtesy of git\n\nI tend to aggressively delete unused code paths during cleanup passes. I lean heavily on carefully crafted git commits in order to make it easy on myself in case I ever need to recover deleted code.\n\nFor each coherent block of code I delete, I make a commit with only that change and a commit message stuffed with relevant keywords that I can later grep on in case of need.\n\nI also try not to touch API boundaries as much as possible, in order to avoid introducing bugs, but if I find unused functions, or branches I’m quick to the delete key.\n\nGCC attributes\nDuring cleanup passes I also like to add GCC-style __attribute__ decorations, as I found quite a few of them can help catch bugs.\n\n__attribute__((warn_unused_result)), for example, is one of my favorite function attributes, as it causes a warning to be emitted if a caller of the function does not use its return value.\n\n__attribute__((pure)) is another attribute I use quite often, more for documentation purposes than for compiler optimization.\n\nA sprinkle of unit tests\n\nThe test suite for Rival Fortress is pretty poor, if I have to be honest, so I try to invest some of the alloted cleanup time to adding some unit tests for algorithmically complex and functions that look like they have poor coverage.\n\nI guesstimate code coverage for a function with the simple terminal onliner: grep FUNCTIONAME | wc -l. This gives me the all the callsites for the function, so I can quickly skim through, and get a feel for the use cases.\n\nOne of these days I’ll have to look into code coverage mapping.\n\n","preview":"After last week’s transition from C++ to C99, I decided to dedicate this week to code cleanup. Re-enabling all warnings My compiler of choice is Clang and I like to...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":7,"type":"post","title":"<b>#41</b>From C++ To C","url":"/rival-fortress-update-41-from-c-to-c/index.html","game":"rival-fortress","date":"Oct 24, 2016","gameName":"Rival Fortress","content":"Over the past couple of months I’ve been working as a consultant on an embedded project written in C99 and I’ve been toying with the idea of transitioning the codebase of Rival Fortress from C++ to plain C.\n\nAs I hinted in a previous post I’m not a big fan of most of the features that C++ offers, and in the past month I realized how much I enjoy the bare bones feel of coding in plain C.\n\nThis weekend I decided to bite the bullet and changed the build script flag from -std=c++11 to -std=c99.\n\nTo my surprise porting the game to C didn’t take too long: I was done in a couple of days.\n\nBye bye overloading\n\nOne of the “features” of C that I never thought I would come to appreciate is the lack of function overloading.\n\nLike many Linux programmers, my home is in the shell, and being able to grep the codebase for a function name and having it return a list of all the exact call sites has been proven to be very useful in more than one occasion.\n\nThe lack of operator overloading does make to code very verbose at times, but I’m the kind of guy that likes long variable and function names, so that’s a plus for me.\n\nSurprise compile times\n\nAnother surprise was the speed up in compilation time. I wasn’t expecting much as I was already light on bloaty C++ features, but after the port the compilation time went from 0.9 seconds to 0.7 in debug mode.\n\nThe codebase is currently at about 95k lines of code for the game and engine plus about 15k for the development tools. Every executable is compiled as a single compilation unit with GNU Make.\n","preview":"Over the past couple of months I’ve been working as a consultant on an embedded project written in C99 and I’ve been toying with the idea of transitioning the codebase...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":8,"type":"post","title":"<b>#40</b>Category-Based Logging Using Bit Masks","url":"/rival-fortress-update-40-category-based-logging-using-bit-masks/index.html","game":"rival-fortress","date":"Oct 22, 2016","gameName":"Rival Fortress","content":"Note: You can find the source code for the bit flag logger generator on Github.\n\nThe logging system I wrote for Metric Panda Engine uses bit masks to support arbitrary composition of logging categories like so:\n\n  Log(INFO, \"One\");                  // Outputs: [INFO ][         ][    ] One\n  Log(ERROR|CATEGORY1, \"Two\");       // Outputs: [ERROR][CATEGORY1][    ] Two\n  Log(CATEGORY1|CAT2, \"Three\");      // Outputs: [     ][CATEGORY1][CAT2] Three\n\nThe Log macro takes a bit mask that is used to filter log messages based on a verbosity mask. The log message, in this case a simple printf, is prepended with a prefix that is generated from the bit mask.\n\nCategory labels used in the log prefix are resolved at compile time, when building in optimized mode, and the only branch is on the verbosity bit-mask.\n\nWhy bit masks\nOther than the fact that, in my opinion, the API is quite comfortable, using bit masks makes pinpoint filtering much easier.\n\nFor example, in Metric Panda Engine I use three log categories, with labels along these lines:\n\n  Severity: VERBOSE, INFO, WARN, ERROR\n  Subsystem: AUDIO, RENDER, NET, INPUT, …\n  Subcategory: INIT, SHUTDOWN, DRAW, SAMPLE, …\n\n\nWhen investigating a particular subsystem, it is quite easy to filter only events related to it, for example by setting the verbosity mask to RENDER|INIT messages of any severity coming from the initialization part of the rendering subsystem are shown.\n\nName collisions\n\nIn order to keep category labels short and easy to type, while also avoiding name collisions, the Log macro looks like this:\n\nenum\n{\n  LOG_VERBOSE        = 1 &lt;&lt;  0,\n  LOG_INFO           = 1 &lt;&lt;  1,\n  LOG_WARN           = 1 &lt;&lt;  2,\n};\n\n#define Log(Flags, ...) \\\n{ \\\n  enum { \\\n    VERBOSE    = LOG_VERBOSE, \\\n    INFO       = LOG_INFO, \\\n    WARN       = LOG_WARN, \\\n  }; \\\n  ... \\\n}\n\nAs you can see, the short labels are “aliases” to longer equivalents with the LOG_ prefix.\nThe shorter labels are confined to the scope of the macro so they don’t leak out causing collisions.\n\nUnfortunately collisions can still occur if macros in the outer scope have the same name as the short labels, like the following example:\n\n#define INIT(X) \n// ...\n  Log(INFO|RENDER|INIT, \"Setting up XYZ\"); // This won't compile\n\nFortunately the collision is detected at compile time, so it can be easily fixed by changing the conflicting log label. In Metric Panda Engine I removed all external includes so I have the luxury of using concise names without fear of collisions.\n\nFiltering log entries\n\nFiltering is done by wrapping the actual logging function in an if statement like so:\n\n#define Log(Flags, ...) \\\n  ... \\\n  if ((Flags) &amp; GlobalVerbosity) { \\\n    DoTheLogging(...); \\\n  } \\\n}\n\nThe GlobalVerbosity variable is an integer that can be set to the desired bit mask. Since the GlobalVerbosity is set outside the macro, the longer version of the log labels are used, like so:\n\nint GlobalVerbosity;\n\nint main()\n{\n  GlobalVerbosity = LOG_INFO | LOG_RENDER | LOG_INIT;\n  // ...\n}\n\nPrinting label strings\n\nIn order to print the labels I’m using simple lookup functions that look like this:\n\nstatic inline const char* LOG_PrioritiesLabel(int Flags)\n{\n  switch (Flags &amp; LOG_PRIORITIES_MASK)\n  {\n    case LOG_VERBOSE:     return \"[VERBOSE]\";\n    case LOG_INFO:        return \"[INFO   ]\";\n    case LOG_WARN:        return \"[WARN   ]\";\n    case LOG_ERROR:       return \"[ERROR  ]\";\n    case LOG_FATAL:       return \"[FATAL  ]\";\n  }\n  return \"[       ]\";\n}\n\nAs I mentioned earlier, this function is trivially collapsed by the compiler since the Flags variable is known at compile time, so there is no cost to this approach.\n\nThe LOG_PRIORITIES_MASK is an integer that masks only the bits that, in this case, make up the priorities labels.\n\nGenerating the logger code\n\nNone of the code I showed is written by hand, it is all generated by the Metareflect system that I talked about in previous posts.\n\nI extracted the relevant bits into a standalone logger generator, loggen that is up on Github.\n\nGive it a try!\n","preview":"Note: You can find the source code for the bit flag logger generator on Github. The logging system I wrote for Metric Panda Engine uses bit masks to support arbitrary...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":9,"type":"post","title":"<b>#39</b>How I Use __COUNTER__ To Localize Text And Hash Strings At Compile Time","url":"/rival-fortress-update-39-how-i-use-__counter__-to-localize-text-and-hash-strings-at-compile-time/index.html","game":"rival-fortress","date":"Oct 14, 2016","gameName":"Rival Fortress","content":"__COUNTER__ is a preprocessor macro available in most compilers that expands to sequential integers starting from zero.\n\nIt resets at the beginning of each new translation unit (i.e. each object file), and is commonly used with the paste (##) operator to create unique identifiers within other macros.\n\nWhile on working on the localization bits for Rival Fortress, I stumbled upon an interesting usage for __COUNTER__ that has allowed me to generate fast localization lookups and string hashing that are resolved at compile time and have an API that looks like this:\n\n#define T(X) Translate(__COUNTER__)\n#define H(X) HashString(__COUNTER__)\n\nvoid SomeFunction()\n{\n  printf(\"%s %u\\n\", T(\"Hello\"), H(\"asset.png\")); // Prints \"Hola 1927298820\"\n}\n\nIn this post I’ll talk about what goes on behind the scenes of the previous snippet of code.\n\nGuaranteed monotonic\n\nI’m compiling the project as a single compilation unit (a.k.a. unity build), meaning all source files are included from one master source. The main advantage of this approach is fast compilation times: the codebase currently clocks in at about 95k LOC and compiles in less than a second in debug mode.\n\nThe other advantage of using a unity build is that __COUNTER__ is guaranteed to be strictly monotonic, meaning no two values it produces are equal.\n\nHaving a unique counter means that lookup tables can become a thing.\n\nLookup tables indexed on compile time constants are trivial to inline by any compiler worth its salt, so that’s exactly what I did.\n\nMetareflect refresher\n\nI previously talked about the custom reflection preprocessor that I implemented in order to automate generation of config files from structs.\n\nAs a refresher, Metareflect, as I’ve called it, is a standalone executable that runs before the compiler, as part of the build process.\n\nIt lexes and parses C code in the same manner as a compiler front end does in the preprocessing phase, and looks for special annotation tokens that look like this:\n\n#define MREFLECT(...)\n\nMREFLECT(Struct)\ntypedef struct MPEConfig\n{\n  MREFLECT(Config = \"Engine\", Default = DEFAULT_FULLSCREEN_MODE)\n  MPEFullscreenMode FullscreenMode;\n} MPEConfig;\n\nAs you can see, the MREFLECT() macro expands to nothing at compile time, but is used as an annotation that Metareflect understands and uses as a directive to generate code.\n\nThe previous snippet, for example, would cause Metareflect to generate the code needed for reading and writing the struct to and from an INI. Config and Default are options that, in this case, tell Metareflect that the configuration setting should be placed in the [Engine] section with a default value of DEFAULT_FULLSCREEN_MODE.\n\nThe generated code is saved in the src/generated/ folder and included by the rest of the codebase. If you are familiar with Unreal Engine, I’ve based Metareflect on their “UPROPERTY” reflection system.\n\nGenerating translation lookup tables\n\nI expanded Metareflect making it generate the code for a lookup table for translation entries using __COUNTER__, and this is what it looks like:\n\n#define T(X) Translate(__COUNTER__)\n\nstatic const char* GlobalTranslationTable[3];\n\ninline const char* Translate(int Counter)\n{\n  switch (Counter)\n  {\n    case 0:\n    case 5:\n    case 7:\n      return GlobalTranslationTable[0];\n    case 2:\n    case 6:\n      return GlobalTranslationTable[1];\n    case 4:\n      return GlobalTranslationTable[2];\n  }\n  // This is never executed\n  return \"\";\n}\n\nThe switch statement maps each __COUNTER__ value to a string. As you can see, it handles duplicate strings by collapsing case statements.\n\nThe number of entries in the GlobalTranslationTable is calculated by Metareflect by counting unique entries passed to the T(X) macro. These entries are stored in a simple hashtable-like data structure that uses the argument of the T(X) macro hashed as a 32 bit unsigned integer as key. Eventual key collision can easily resolved by adding a second parameter to the macro and using it as seed for the hash function.\n\nGlobalTranslationTable is populated at runtime from either from the default char* array, that contains the entries found in the source code or from a binary localization file, also generated by Metareflect. Changing language is simply a matter of memcpy-ing the correct translation table over the global.\n\nThis approach is very fast, as the Translate function is guaranteed to be inlined because Counter is known at compile time. The compiler will replace each call to Translate with a mov instruction pointing to the offset in the GlobalTranslationTable that in turn contains a pointer to the localized string.\n\nOutputting Translator friendly CSV files\n\nUsing Metareflect I’m also generating CSV files for translators. The CSVs use the argument of the T(X) macro as key, so the binary translation file can be remapped to the correct __COUNTER__ even if the lines of code are swapped. This is a one time operation that happens on startup.\n\nHashing strings at compile time\n\nLeveraging the same code that generates translation lookup tables, I was also able to make lookup tables for string hashes that look like this:\n\n#define H(X) HashString(__COUNTER__)\n\nstatic uint32_t GlobalStringHashTable[2];\n\ninline uint32_t HashString(int Counter)\n{\n  switch (Counter)\n  {\n    case 1:\n    case 3:\n      return GlobalStringHashTable[0];\n    case 8:\n      return GlobalStringHashTable[1];\n  }\n  // This is never executed\n  return 0;\n}\n\nThis function is also easily inlined by the compiler so it collapses down to just numbers that replace the macro invocations.\n\nDoes it slow down compilation time\n\nNo. Currently Metareflect is able to do its thing in less than 40ms, spitting out about 15k LOC that include code generated for custom data structures, allocators, INI/JSON reader/writers, networking and more.\n\n","preview":"__COUNTER__ is a preprocessor macro available in most compilers that expands to sequential integers starting from zero. It resets at the beginning of each new translation unit (i.e. each object...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":10,"type":"post","title":"<b>#38</b>Include Detective: Keep An Eye On Those Includes","url":"/rival-fortress-update-38-include-detective-keep-an-eye-on-those-includes/index.html","game":"rival-fortress","date":"Oct 3, 2016","gameName":"Rival Fortress","content":"Note: You can find the source code for Include Detective on Github.\n\nThis weekend I wrote a little Bash script to investigate include chains of some system headers, and it turned out to be pretty useful, so that’s what I’ll talk about in this post.\n\nThis is what Include Detective looks like in action:\n\n\n\n\nHow does it work?\n\nInclude Detective is a bash script that runs the compiler on a dummy C or C++ file with just an #include directive. The #include points to the path or system header specified as argument to the script.\n\nThe compiler (GCC and Clang family of compilers) is invoked twice with flags -E and -dM.\n\nThe -E flag stops compilation after the preprocessing stage, resulting in an output where all headers have been inlined and preprocessor directives and macros expanded.\n\nThe -dM flag tells the compiler to dump all preprocessor defines (both builtin and the ones defined in the included files).\n\nThese outputs are then parsed and statistics printed as you can see above.\n\nThe source of the preprocessed file can be dumped by passing the -p (for print) before the filename. The following is the output from running include-detective -p assert.h:\n\n# 1 \"&lt;stdin&gt;\"\n# 1 \"&lt;built-in&gt;\"\n# 1 \"&lt;command-line&gt;\"\n# 31 \"&lt;command-line&gt;\"\n# 1 \"/usr/include/stdc-predef.h\" 1 3 4\n# 32 \"&lt;command-line&gt;\" 2\n# 1 \"&lt;stdin&gt;\"\n# 1 \"/usr/include/assert.h\" 1 3 4\n# 35 \"/usr/include/assert.h\" 3 4\n# 1 \"/usr/include/features.h\" 1 3 4\n# 368 \"/usr/include/features.h\" 3 4\n# 1 \"/usr/include/sys/cdefs.h\" 1 3 4\n# 415 \"/usr/include/sys/cdefs.h\" 3 4\n# 1 \"/usr/include/bits/wordsize.h\" 1 3 4\n# 416 \"/usr/include/sys/cdefs.h\" 2 3 4\n# 369 \"/usr/include/features.h\" 2 3 4\n# 392 \"/usr/include/features.h\" 3 4\n# 1 \"/usr/include/gnu/stubs.h\" 1 3 4\n# 10 \"/usr/include/gnu/stubs.h\" 3 4\n# 1 \"/usr/include/gnu/stubs-64.h\" 1 3 4\n# 11 \"/usr/include/gnu/stubs.h\" 2 3 4\n# 393 \"/usr/include/features.h\" 2 3 4\n# 36 \"/usr/include/assert.h\" 2 3 4\n# 64 \"/usr/include/assert.h\" 3 4\n# 67 \"/usr/include/assert.h\" 3 4\nextern void __assert_fail (const char *__assertion, const char *__file,\n      unsigned int __line, const char *__function)\n     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));\nextern void __assert_perror_fail (int __errnum, const char *__file,\n      unsigned int __line, const char *__function)\n     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));\nextern void __assert (const char *__assertion, const char *__file, int __line)\n     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));\n# 1 \"&lt;stdin&gt;\" 2\n\nThe lines beginning with # are special directives that the compiler inserts for debug purposes. You can read more about them on the GCC man page.\n\nWhy is it useful?\n\nInclude Detective can be useful when you are looking to eliminate headers in order to speed up compile times when using single translation unit builds, in favor of precompiled headers.\n\nSome headers are fine, because you end up using most of the symbols they define.\n\nOther headers not so much. Maybe they are huge and you only need the prototypes of a couple of functions; or maybe they recursively include many other headers, unnecessarily slowing down compile times.\n\nIn cases like this, it may be worth the effort to create your own minimal header that contains only the declarations you care about.\n\nA word of caution: removing a header and replacing it with your own slimmed-out version, requires you to make sure that the function prototypes or preprocessor defines are correct for all the architectures you are shipping to.\n\nA simple example of “debloating”\n\nHere is a simple example of how you would go about eliminating a header dependency with your own slim version using the classic “Hello World, using both plain C and C++.\n\n// C++\n#include &lt;iostream&gt;\n\nint main()\n{\n  std::cout &lt;&lt; \"Hello World!\" &lt;&lt; std::endl;\n}\n\n\n\n\nAs you can see, the C++ program gets expanded into more than 17000 lines of code, included from 134 files. This process has to be done every time you compile. Quite crazy, if you only need a small subset of what’s declared in the header.\n\n// C\n#include &lt;stdio.h&gt;\nint main()\n{\n  printf(\"Hello World!\\n\");\n}\n\n\n\n\nThe C equivalent is much saner, with only 295 lines of code and 16 includes. Still, we are only calling a function, do we really need all that noise?\n\nRemoving the header in plain C\n\nWhen coding in plain C the process is very easy, you just have to run Include Detective on the header you are interested in removing, and grep for the functions or #defines that you need:\n\ninclude-detective -p stdio.h | grep printf -A 1\n\nNotice that I used the -p flag, meaning the preprocessed header will be prited to stdout. Next I pipe the result to grep searching for printf and using the -A 1 option, to tell grep that I want one line of context after each match, because I know that most function declarations in GCC’s headers span two or three lines.\n\nThis is the relevant output is:\n\nextern int printf (const char *__restrict __format, ...);\n\nNow all you have to do is copy and paste that line into the source file like so:\n\nextern int printf (const char *__restrict __format, ...);\nint main()\n{\n  printf(\"Hello World!\\n\");\n}\n\nNo more #include &lt;stdio.h&gt; and this will compile just fine.\n\nObviously you are not getting rid of the Standard Library, because the linker will still link to it, but the preprocessor stage of the compilation will be faster.\nIn this simple case the speed increase is irrelevant, but as the number of includes grows, you will see a much larger benefit.\n\nRemoving the header in C++\n\nWell… Doing the same for the C++ example is quite a nightmare, as you can imagine from the fact that #include &lt;iostream&gt; brings in 17k lines of code.\n\nI wouldn’t recommend doing it manually but if you figure out a smart way to automate it you can follow this process:\n\n\n  \n    output the preprocessed header with the -p option and using MODE=cxx to tell Include Detective that it’s working with C++ like so:\n\n    MODE=c++ include-detective -p iostream &gt; iostream-dump.cc\n  \n  \n    using iostream-dump.cc reconstruct the chain of class/template/typedef that make cout and endl possible, and copy them in your minimal include header\n  \n\n\nThe resulting header will not be a one-liner like in the C case, but it will certainly not be 17000 lines of code!\n\n","preview":"Note: You can find the source code for Include Detective on Github. This weekend I wrote a little Bash script to investigate include chains of some system headers, and it...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":11,"type":"post","title":"<b>#37</b>Git Subtrees","url":"/rival-fortress-update-37-git-subtrees/index.html","game":"rival-fortress","date":"Sep 29, 2016","gameName":"Rival Fortress","content":"I share Metric Panda’s Engine code with multiple projects, and since I’m actively adding features to it I often tend to make changes or fix bugs while working on the parent project.\n\nI use Git for source control and it is important for me to be able to make commits to either the engine or the parent repository separately and cleanly.\n\nThe most common use case is: I’m working on some feature in the parent project, I spot a bug in the nested project that I fix, and without having to commit anything to the parent project, I want to be able to commit the bugfix to the child project.\n\nIn this post I’ll talk about common ways to solve this problem using Git.\n\nThe ugly\n\nThe naive solution is to copy or symlink code and manually copy changes to the nested code to all projects. This becomes a nightmare quickly as things can get out of sync because of human error. Also, it becomes harder to track bugs using tools git bisect when the parent repository’s history contains commits relating to the child repository.\n\nThe bad\nThe second solution is to use git submodules. Unfortunately submodules are a less than ideal solution for simple use cases like mine and they bring along a lot of baggage and overhead that often times gets in the way and makes the workflow more complicated.\n\nThe problem with Git submodules has been summarized perfectly by Oren Eini’s blog post:\n\n\n  \n    You can’t just git clone the repository, you need to clone the repository, then call git submodule init &amp; git submodule update.\n    You can’t just download the entire source code from Github.\n    You can’t branch easily with submodules, well, you can, but you have to branch in the related projects as well. And that assumes that you have access to them.\n    You can’t fork easily with submodules, well, you can, if you really feel like updating the associations all the time. Which is really nasty.\n  \n\n\nThe good\nSince I started working on Rival Fortress I’ve been using git subtrees as a way to embed the engine in various projects.\n\nThe thing I like about subtrees is that the workflow is much cleaner:\n\n  the code for the engine is “embedded” directly in the source tree of the parent project,\n  both repositories have a separate commit history,\n  it is easy to freeze the engine repository to a particular commit\n  when a bugfix is made in the engine’s repository it can be easily pushed from within the parent project\n\n\nSubtrees aren’t perfect, though. I’ve had some issues with having to manually resolve merge conflicts when updating the subtree and the commands to manage a subtree are impossible to remember, and if you execute the wrong command you can clobber code on the remote repository, so tread carefully.\n\n","preview":"I share Metric Panda’s Engine code with multiple projects, and since I’m actively adding features to it I often tend to make changes or fix bugs while working on the...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":12,"type":"post","title":"<b>#36</b>Chronicle of Optimization with perf and C","url":"/rival-fortress-update-36-chronicle-of-optimization-with-perf-and-c/index.html","game":"rival-fortress","date":"Sep 22, 2016","gameName":"Rival Fortress","content":"Note: You can find the source code for the optimized version of poly2tri on Github.\n\nI needed a fast and robust mesh triangulation solution for Metric Panda Engine and after some research I found the excellent  Poly2Tri library, an implementation in C++ of the Sweep-line algorithm for constrained Delaunay triangulation.\n\nMetric Panda Engine is written in C-style C++, so I wanted to port the code for poly2tri and customize it to fit the engine’s needs.\n\nWhile I ported the code I noticed opportunities for optimization, and in this post I’ll talk about what I did.\n\n\n\n\nPreparing the library for profiling\n\nBefore I went ahead and made changes I wanted a baseline profile measurement.\n\nFortunately Poly2tri comes with a testbed with sample data that can be used to test the output of the library.\nThe test application accepts a data file containing a list of point as input, runs the triangulation routine and displays the result using OpenGL.\n\nThe part I was interested in optimizing was the triangulation routine, so everything else that the test application did was noise that I had to minimize in order to get better readings while profiling.\n\nTo do so I modified the main.cc and did the following:\n\n  Removed the OpenGL visualization part\n  Isolated all library related function calls and placed them in a loop to reduce the noise from the startup of the testbed application\n\n\nThe relevant part of the refactored testbed looks like this:\n\n  for (int Iteration = 0; Iteration &lt; MAX_ITERATIONS; ++Iteration)\n  {\n    CDT cdt = CDT(polyline);\n    cdt.Triangulate();\n    ClearIteration(polyline);\n  }\n\nNote: The snippet above contained a call to new and delete in the initial version of the post. Creating the CDT on the stack saves the call to malloc and shaves off a little time from the benchmarked times.\n\nBird’s eye view with perf stat\n\nWith Poly2tri ready to be profiled I jumped to my trusty perf, the profiling swiss army knife every Linux dev should have in their toolbox. On Windows, the best solution in probably Intel’s VTune, but I don’t have any experience with it.\n\nThe first perf subcommand I always start with is stat:\n\ntaskset 2 perf stat --detailed --repeat 10 ./main testbed/data/debug2.dat 0 0 1\n\nSeveral things are happening in this one-liner:\n\n\n  \n    The taskset 2 will force the perf execution to happen on the second CPU core and avoid any random core migration that may muddy up the results. This can be safely done when dealing with single-threaded code, like it’s the case for Poly2tri.\n  \n  The perf stat command runs the Poly2tri executable (./main) passing it debug2.dat, a test data file containing 10000 points to triangulate.\n  The --detailed flag will cause perf to output more counters.\n  The --repeat 10 flag reruns the executable ten times and averages the results as well as printing the standard deviation between each run.\n  The 0 0 1 at the end are arguments that Poly2tri needs for the OpenGL visualization, but are not used in the modified testbed.\n\n\nThis is the result with the interesting parts highlighted:\n\n\n\n\n\n  \n    The first highlighted row shows the execution time in milliseconds. The rightmost column is the standard deviation between runs. A low standard deviation means the program is stable across runs.\n  \n  \n    The second highlighted row shows the instructions per cycle, an important metric that can give you hints on whether the CPU is stalling during execution.\n\n    The Intel® 64 and IA-32 Architectures Optimization Reference Manual defines this metric as Clocks per Instructions Retired Ratio (CPI), and uses the inverse of what perf shows. The theoretical best on modern superscalar CPUs executing at full speed is 4 instructions per cycle. In the case of Poly2tri, 1.29 instructions per cycle indicate possible front-end or back-end stalls. A deeper analysis is required. Take a look at Tuning Applications Using a Top-down Microarchitecture Analysis Method for more on the subject.\n  \n  \n    The third highlighted row shows the number of L1 cache misses. Perf highlighted the percentage in yellow to indicate that this may be a potential hotspot and should be investigated further.\n  \n\n\nFinding the hot spots with perf report\n\nNow that I had a baseline to work with, I used the next perf subcommand: record.\n\ntaskset 2 perf record -e cpu-clock,L1-dcache-load-misses ./main testbed/data/debug2.dat 0 0 1\n\nThe previous command will sample the execution of the program and read the event counters specified by the -e flag:\n\n\n  cpu-clock: measures the time spent in a function. This is useful for gauging the amount the functions we should be focusing on.\n  L1-dcache-load-misses: will show the functions that triggered the most L1 cache misses\n\n\nThe recorded data can be viewed with perf report and looks like this:\n\n\n\n\nThe first set represents the top 5 functions sorted by cpu-clock with the percentage column on the left that indicates the amount of time spent overall.\nThe second set of functions represent where L1 cache misses happened.\n\nThe functions of interest that appear in both sets are:\n\n  p2t::Triangle::MarkNeighbor: (see on Github) marks a triangle as a neighbor if they share two points along an edge.\n  __ieee754_atan2_avx: (see on Github) is the libm implementation of the atan2 function.\n  p2t::AdvancingFront::LocateNode: (see on Github) traverses the doubly-linked-list of the advancing front looking for the next node to process.\n\n\nDigging deeper with perf annotate\n\nNow that we have a few hot spots to look at, we can fire up another perf subcommand: annotate.\n\nActually, instead of calling annotate directly, I find it easier to jump to it from perf report by selecting the function of interest and pressing a.\n\nCycling through the hottest instructions in the report for cpu-clock of p2t::Triangle::MarkNeighbor (by pressing TAB), most of hot spots are caused by this:\n\n\n\n\nIt corresponds to the function p2t::Triangle::Contains (see on Github) that is inlined by the optimizer.\n\nThe reason the cmp %rcx,%rdx takes up so many cycles is probably because of a CPU stall caused by either a cache miss or another dependent instruction.\n\nLooking the report for L1-dcache-load-misses seems to confirm the suspicion:\n\n\n\n\nThe other function on the hot spot list, p2t::AdvancingFront::LocateNode, also suffers from a similar issue: the CPU is having to wait for memory access because of heavy usage of doubly linked lists.\n\nWays to optimize these sorts of CPU stalls involve improving the cache locality of the data (i.e. keep the data that needs to be worked on closer together in memory). This can’t always be done directly if the underlying algorithm has certain constraints, but often times there is a better way.\n\nAn excellent video on the subject is Mike Acton’s great Data-Oriented Design and C++ talk.\n\nTime to Optimize\n\nBefore I went about focusing on optimizing cache locality, I wanted to go for the low hanging fruits.\n\nBye bye new and push_back\n\nFor the first optimization pass I decided to remove all dynamic allocations caused by calls to std::vector.push_back and new. I never use dynamic allocation in performance critical code, and instead use many types of custom allocators depending on the needs.\n\nI replaced these allocations with a simple fixed-size push allocator that partitions a large memory block that is passed in to the library during initialization.\nThe push allocator looks something like this:\n\nvoid* Push(PolyPushAllocator* Allocator, size_t Size, size_t AlignmentInBytes)\n{\n  void* Result = 0;\n  size_t AlignmentOffset = 0;\n  size_t MemoryAddress = (size_t)Allocator-&gt;Memory;\n  if(MemoryAddress &amp; (AlignmentInBytes-1))\n  {\n    AlignmentOffset = AlignmentInBytes - (MemoryAddress &amp; (AlignmentInBytes-1));\n  }\n  Size += AlignmentOffset;\n  if (Allocator-&gt;Used + Size &lt;= Allocator-&gt;Size)\n  {\n    Result = Allocator-&gt;Memory + (Allocator-&gt;Used + AlignmentOffset);\n    Allocator-&gt;Used += Size;\n  }\n  return Result;\n}\n\nAs you can see, it’s very simple and is lightning fast compared to malloc/new.\n\nThis optimization resulted in a ~39% performance increase from the baseline on the debug2.dat file and is proportional to the number of points the library has to process: the more points in the data set there are, the slower dynamic allocations will become.\n\n\n\n\nDoubles to floats\n\nThe next optimization I had on my checklist was changing the type for floating point from double to float.\n\nMy assumption was that since the precision of 64bit floating point numbers was not needed for this type of library, why not use floats and allow the CPU potentially increase bandwidth and parallelization.\n\nThe result was a tiny improvement in performance, mostly because the algorithm doesn’t do any wide operations of floating point numbers that would benefit from the increased bandwidth.\n\n\n\n\nFaster Atan2 function\n\nAs seen above, the atan2 is one of the hot spots of Poly2tri, so I tried to replace it with an approximate version of the function with a good enough error.\n\nThe implementation I ended up with is based on this fast atan2 approximation and has a maximum error of 0.005 radians. That is perfectly acceptable for my needs.\n\n\n\n\nOptimizing Cache Misses\n\nThe last item on my list was cache misses.\n\nWhile working on the previous optimizations I gained a better understanding on the algorithm Poly2tri is aimed at implementing.\nThe heavy usage of linked lists and double pointers was a sensible decision by the original implementer, and honestly I can’t really thing of a more performant way of doing things.\n\nIn the end I tried my best to reduce cache pressure with micro optimizations here and there. The final result is acceptable, but code in some sections may have become more cryptic for people trying to understand the algorithm.\n\nThis is what I did:\n\n  Replaced the std::vector to the Edges in pt2::Point to a linked list. The edges initialized are once and not accessed often, so this change allowed for easier memory management.\n  Replaced the bool arrays on pt2::Triangle (see on Github) with an unsigned int field that is used as a bit mask. The advantage is that bit operations are very cheap and avoid may of the branches used in the original implementation.\n  Removed many of the branches that caused cache misses like the one showcased earlier.\n  Used a global lookup table for faster access of triangle array indices when rotating left or right from a point.\n\n\nThe final, optimized, result on the debug2.dat sample data with 100 iterations resulted in ~100% speed increase:\n\n\n\n\n","preview":"Note: You can find the source code for the optimized version of poly2tri on Github. I needed a fast and robust mesh triangulation solution for Metric Panda Engine and after...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":13,"type":"post","title":"Tips for Productive Debugging with GDB","url":"/tips-for-productive-debugging-with-gdb/index.html","game":"","date":"Sep 12, 2016","gameName":"","content":"In this post I’ll share my favorite tips for getting the most out of GDB.\n\nTip #1: Try GDB Dashboard\nThis may or may not be your cup of tea, but if, like me, you like having access to more program information at every break stop you may want to try GDB Dashboard.\n\nIt is a fantastic modular interface that comes as a .gdbinit replacement and, with all modules enabled, looks like this:\n\n\n\n\nTake a look at the Github repository for the project for more information on how to customize it to fit your needs.\n\nTip #2: Use a global .gdbinit and a project .gdbinit\n\n.gdbinit is the configuration file that gdb sources at startup. You can have one in your home directory (~/.gdbinit) for global settings, and one in the current directory (./.gdbinit) for project specific settings.\n\nAs you will see from the following tips, project specific settings for gdb can be useful for custom formatters or aliases.\n\nNote: you must enable project specific .gdbinit files with the set auto-load local-gdbinit.\n\nTip #3: Use custom formatters\n\nCustom C/C++ types can be noisy to inspect in the debugger, especially if implemented using unions.\n\nWith gdb’s Pretty Printing you can define custom formatters for your data types in order to make them more readable.\n\nFor example, in Rival Fortress I have a matrix data type (MPEMatrix4) that is a union of many anonymous structs for developer convenience. This is what it looks like before and after using a custom print formatter:\n\n\n\n\nAnd this is the source for the custom formatter:\n\nclass MPEMatrixPrinter:\n  \"\"\"Print a 4x4 matrix.\"\"\"\n\n  def __init__(self, val, size):\n    self.val = val\n    self.size = int(size)\n\n  def to_string(self):\n    return (\"\\n\\t[ %3g %3g %3g %3g ]\"\n            \"\\n\\t[ %3g %3g %3g %3g ]\"\n            \"\\n\\t[ %3g %3g %3g %3g ]\"\n            \"\\n\\t[ %3g %3g %3g %3g ]\") % \\\n                (float(self.val[\"flat\"][0]), float(self.val[\"flat\"][1]), float(self.val[\"flat\"][2]), float(self.val[\"flat\"][3]),\n                float(self.val[\"flat\"][4]), float(self.val[\"flat\"][5]), float(self.val[\"flat\"][6]), float(self.val[\"flat\"][7]),\n                float(self.val[\"flat\"][8]), float(self.val[\"flat\"][9]), float(self.val[\"flat\"][10]), float(self.val[\"flat\"][11]),\n                float(self.val[\"flat\"][12]), float(self.val[\"flat\"][13]), float(self.val[\"flat\"][14]), float(self.val[\"flat\"][15]))\n\ndef project_type_lookups(val):\n  lookup_tag = val.type.tag\n  if lookup_tag == None:\n    return None\n\n  match = re.match(r\"^MPEMatrix(\\d)$\", lookup_tag)\n  if match:\n    return MPEMatrixPrinter(val, match.group(1))\n\ngdb.pretty_printers.append(project_type_lookups)\n\nIt assumes that the matrix type has a flat[16] member field.\n\nTip #4: Use aliases\n\nAliases are an excellent way to speed up your day to day debugging. You specify them in your .gdbinit and look like this:\n\nalias -a w = dashboard expression watch\n\nTip #5: Use automatic $ variables\n\nWhenever you inspect something using the print command, gdb automatically stores the result in a variable like so:\n\n&gt;&gt;&gt; print Identity\n$1 = \n        [   1   0   0   0 ]\n        [   0   1   0   0 ]\n        [   0   0   1   0 ]\n        [   0   0   0   1 ]\n\nThe $1 is the automatic variable, and you can reference it later like so:\n\n&gt;&gt;&gt; print $1\n$2 = \n        [   1   0   0   0 ]\n        [   0   1   0   0 ]\n        [   0   0   1   0 ]\n        [   0   0   0   1 ]\n\nTip #6: Inspect array pointers\n\nWhen working with plain C-style pointer to an array you can use the following command:\n\n&gt;&gt;&gt; print *Array@10\n\nThis will print 10 items from the Array pointer.\n\nTip #7: Enable command history\n\nEnable command history by adding the following to your .gdbinit:\n\nset history save on\n\nBy default the history file (.gdb_history) is saved in the current directory, but if you want you can share histories by explicitly setting the output filename with set history filename &lt;fname&gt;.\n\nTip #8: Detect if the debugger is running\n\nThis is not really a gdb specific tip, but it is useful nonetheless.\n\nOn Windows you can use the IsDebuggerPresent function to detect if a debugger is running. You can do the same on Unix-like systems using the following function:\n\n  #ifndef _WIN32\n  #include &lt;sys/ptrace.h&gt;\n  static int IsDebuggerPresent()\n  {\n    static int Detected;\n    static int RunningUnderDebugger;\n    if (!Detected)\n    {\n      Detected = 1;\n      RunningUnderDebugger = ptrace(PTRACE_TRACEME, 0, 0, 0) == -1;\n    }\n    return RunningUnderDebugger;\n  }\n  #endif\n\n","preview":"In this post I’ll share my favorite tips for getting the most out of GDB. Tip #1: Try GDB Dashboard This may or may not be your cup of tea,...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;other&quot;]"},{"id":14,"type":"post","title":"<b>#36</b>Simple Crash Resurrection For C/C++ Game Engines","url":"/rival-fortress-update-35-crash-resurrection-for-c-cpp-game-engines/index.html","game":"rival-fortress","date":"Sep 5, 2016","gameName":"Rival Fortress","content":"The video demonstrates the crash resurrection functionality in Metric Panda Engine.\n\n\n\nCrash resurrection of Metric Panda EngineRead More \n\n\nA simple feature that, by using the engine’s hot reloading functionality, reloads a previous version of the game .dll/.so when a crash occurs.\n\nThis is development only feature, that gives you a chance to quickly correct simple mistakes while debugging that would otherwise cause you to lose the state of the game.\n\nI would strongly suggest against doing such shenanigans in shipping builds.\n\nImplementing Crash Resurrection in Your Engine\n\nThe process of gracefully recovering from most crashes is simple and can be broken up in the following steps:\n\n\n  Step 0: Prerequisite: Hot reloading\n  Step 1: Backup the previous .dll\n  Step 2a: Add a crash handler on Linux/Mac\n  Step 2b: Add a crash handler on Windows\n  Step 3: Augment the Hot Reload functionality\n  Step 4: What about the debugger\n\n\nI’ll be referring to dll for simplicity when talking about shared libraries, but replace it with the extension used by your OS.\n\nStep 0: Prerequisite: Hot reloading\n\nHot reloading or Live Code Editing is the act of unloading and reloading a shared library without having to restart the main application. This is usually done whenever a newer version of the shared library is detected.\n\nIf you have used Unreal Engine or watched Casey Muratori’s excellent Handmade Hero series, you know how useful this feature can be, especially when rapidly iterating over code that needs to feel “just right”.\n\nIf your engine supports hot reloading read on, otherwise take a look at Handmade Hero’s Day 22: Instantenous Live Code Editing for a Windows implementation, and Interactive Programming in C by Chris Wellons, for Unix-like systems.\n\nStep 1: Backup the previous .dll\n\nIn your build script, before your game library compilation step, make a backup of the previous version of the .dll, for example copy it to game-backup.dll.\n\nYou also have to check if the backup is being used by the game because of a recent crash. If this is the case you shouldn’t clobber it as the new code you are about to compile may crash too.\nYou can do this check using the lsof command on Unix-like systems and Handle on Windows.\n\nFor example you could use the following bash script on Unix-like systems:\n\n#!/bin/bash\n\nsource_lib=game.so\nbackup_lib=game-backup.so\n\n# Copy $source_lib to $backup_lib only if:\n#  - $source_lib exists and\n#  - $backup_lib is not open by a process\nif [[ -f \"$source_lib\" &amp;&amp; ! \"$(lsof $backup_lib 2&gt; /dev/null)\" ]]; then cp $source_lib $backup_lib; fi\n\nI’m not really a Windows batch or PowerShell wizard, so I’ll leave the Windows implementation as an exercise for the reader.\n\nStep 2a: Add a crash handler on Linux/Mac\n\nOn most Unix-like systems you can use POSIX Signals to recover from crashes.\nFor example, the following code registers a signal handler for SIGSEGV and SIGILL, as I’ve found they are the most common and easily recoverable from, but you can register for any signal you are interested in handling.\n\n#include &lt;signal.h&gt;\n#include &lt;setjmp.h&gt;\n\nsigjmp_buf RecoveryMarker;\nint GameRunning;\n\nint ReloadGameCode(int UseBackup);\n\nvoid SignalHandler(i32 Signal)\n{\n  siglongjmp(RecoveryMarker, -1);\n}\n\nint main(void)\n{\n  struct sigaction SignalAction = {};\n  SignalAction.sa_handler = &amp;CrashHandler;\n  sigemptyset(&amp;SignalAction.sa_mask);\n  sigaction(SIGSEGV, &amp;SignalAction, 0);\n  sigaction(SIGILL, &amp;SignalAction, 0);\n\n  if(sigsetjmp(RecoveryMarker, 0) != 0)\n  {\n    if (!ReloadGameCode(1))\n    {\n      exit(EXIT_FAILURE);\n    }\n  }\n\n  while (GameRunning)\n  {\n    // Game loop\n  }\n  return 0;\n}\n\nStep 2b: Add a crash handler on Windows\n\nWindows provides the Structured Exception Handling (SEH) mechanisms that you can use to recover from a crash.\n\nThe following example is more or less equivalent to the Linux/Mac implementation presented above. I hope you don’t get heart palpitations at the sight of a goto statement ;-).\n\nint GameRunning;\n\nint ReloadGameCode(int UseBackup)\n\nint main(void)\n{\nRecoveryMarker:\n  __try\n  {\n    while (GameRunning)\n    {\n      // Game loop\n    }\n  }\n  __finally\n  {\n    // Can use __except along with GetExceptionCode() and GetExceptionInformation() \n    // to see if exception can be recovered from\n    if (ReloadGameCode(1))\n    {\n      goto RecoveryMarker;\n    }\n  }\n  return 0;\n}\n\nStep 3: Augment the Hot Reload functionality\n\nThe ReloadGameCode function stubbed in the previous examples is in charge of hot reloading the game .dll. In its simplest form it can receive an argument receive an argument that tells it whether or not to reload the main .dll or a backup, like so:\n\nint ReloadGameCode(int UseBackup)\n{\n  int Success = 0;\n  const char* Filename;\n  if (UseBackup)\n  {\n    Filename = \"game-backup.dll\";\n  }\n  else\n  {\n    Filename = \"game.dll\";\n  }\n  // Unload and reload shared library here. See references in\n  // Step 0: Prerequisite: Hot reloading\n  // for sample implementations\n  Success = ...;\n\n  return Success;\n}\n\nStep 4: What about the debugger\n\nWith GDB and GDB frontends, you can disable automatic breakpoints for specific signals using the handle command (like I do in the demo video for SIGSEGV).\n\nI’m not sure how to do the same in Visual Studio, as I don’t tend to use it much, but I guess there’s a similar feature… hopefully…maybe… I don’t know, sorry! :o(\n\n","preview":"The video demonstrates the crash resurrection functionality in Metric Panda Engine. Crash resurrection of Metric Panda EngineRead More A simple feature that, by using the engine’s hot reloading functionality, reloads...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":15,"type":"post","title":"<b>#35</b>Avoiding Automatic Structure Padding in C","url":"/rival-fortress-update-35-avoiding-automatic-structure-padding-in-c/index.html","game":"rival-fortress","date":"Aug 29, 2016","gameName":"Rival Fortress","content":"Note: This post is x86 centric. On other architectures your mileage may vary.\n\nCompiling with the -Wpadded flag on GCC/Clang or -we4820 -we4121 on MSVC, warns you when the compiler inserts padding in your structs.\n\nThese warnings are off by default, because in most circumstances automatic padding is quite convenient, but if you are writing high performance code or embedded systems, padding explicitly and trying to avoid padding may be the better choice.\n\nWhy compiler padding is a thing\nCompilers insert padding to keep data structures aligned, thus avoiding misaligned reads and making memory access faster.\n\nThe rules for when compilers insert padding depend on the target architecture’s word size and the size of each member field in relation to the following member as explained on “Typical alignment of C structs on x86”.\n\nIf the structure contains members with explicit alignment (i.e. types declared with __attribute__((aligned(n))) on GCC/Clang or __declspec(align(n)) on MSVC), then the compiler will take that in consideration when padding.\n\nExamples of automatic padding\nTake the following structure:\n\ntypedef struct Paddee\n{\n  char X; // 1 byte\n  int Y;  // 4 bytes\n} Paddee;\n\nIt is compiled on x86_64 into an equivalent of the following:\n\ntypedef struct Paddee\n{\n  char X;                    // 1 byte\n  char _COMPILER_PADDING[3]; // 3 bytes (invisible)\n  int Y;                     // 4 bytes\n} Paddee;\n\nThe member field _COMPILER_PADDING is not really there, but it is as if it was there, because the compiler inserted the 3 bytes of padding between X and Y. If you compile the struct yourself and check sizeof(Paddee) you will see that it is 8 bytes, not 5.\n\nThe padding is also added at the tail end of the struct, so if you rearrange the members the compiler will pad like so:\n\ntypedef struct Paddee\n{\n  int Y;                     // 4 bytes\n  char X;                    // 1 byte\n  char _COMPILER_PADDING[3]; // 3 bytes (invisible)\n} Paddee;\n\nFor a more realistic example, in the game engine for Rival Fortress I have a 4x4 matrix type that looks something like this:\n\nMS_ALIGN(16) typedef union MPEMatrix4\n{\n  struct\n  {\n    MPEVec4 Col1;\n    MPEVec4 Col2;\n    MPEVec4 Col3;\n    MPEVec4 Col4;\n  };\n  struct\n  {\n    SIMDVec SIMDCol1;\n    SIMDVec SIMDCol2;\n    SIMDVec SIMDCol3;\n    SIMDVec SIMDCol4;\n  };\n  MPEVec4 VecColumns[4];\n  SIMDVec SIMDColumns[4];\n  f32 Flat[16];\n} MPEMatrix4 GCC_ALIGN(16);\n\nThe MS_ALIGN and GCC_ALIGN expand to GCC/Clang or MSVC alignment macros. They tell the compiler that this type should always be aligned to 16 byte boundaries (in order to play nice with SSE instructions).\n\nBecause of the forced alignment constraint every other type that includes MPEMatrix4 as a member will inherit its alignment requirement.\nFor example, the following dummy type:\n\nstruct MPEExample\n{\n  MPEMatrix4 Model; // 16 bytes\n  u32 Flags;        // 4 bytes\n  u8 _PADDING[12];  // 12 bytes\n};\n\nRequires 12 bytes of padding(!) in order to be properly aligned. \nThis translates into a lot of wasted memory bandwidth when dealing with arrays with thousands of entries, like for example entities in a game.\n\nThe solution, in an extreme case like this, is to either rethink the MPEExample and move the Flags field somewhere else (maybe a parallel array that you loop through before or after), or fill the 12 empty bytes with useful data in order to eliminate the wasted memory.\n\nTips for eliminating compiler padding\n\nYou avoid automatic padding by making the compiler happy and aligning your structures optimally. The -Wpadded compiler flag is your guide in knowing when a structure needs better alignment.\n\nThe common ways to align structures manually are:\n\n\n  Rearrange fields: reorder the field in order to maximize packing. I don’t know about GCC and MSVC, but Clang warns you about misaligned fields, so you know where the problem is.\n  Group small types: grouping chars, shorts and ints after larger types, like pointers, can lead to better alignment.\n  Use smaller/bigger types: when possible choose different primitive types, like a uint16_t instead of an int, or a size_t instead of an uint32_t. You can then tie this back to the previous tip about grouping small types.\n  Insert dummy fields: the last resort is to insert fields in your structs between members that require alignment or at the end of the struct. This is what the compiler does, but by doing yourself you have a reminder that you can act on when you modify the struct. I usually add a byte array named _PADDING of the size required to reach alignment.\n\n\nKeep in mind that for large structures, cache line size becomes relevant, so try not to not break groups of fields that you want pulled into the same cache line when restructuring your structs.\n\nThe excellent post The Lost Art of C Structure Packing goes in detail on how to optimally pack structures in C.\n\nWhat to do when you can’t align, but don’t want padding\n\nPadding is not always a good thing. For example when serializing data types to disk or over the network, it is often better to keep structures tightly packed even if it causes unaligned memory reads.\n\nTo selectively disable padding you can use the #pragma pack directive like so:\n\n#pragma pack(push, 1)\nstruct MPEExample\n{\n  MPEMatrix4 Model; // 16 bytes\n  u32 Flags;        // 4 bytes\n  // No padding\n};\n#pragma pack(pop)\n\nThis will disable compiler padding and keep sizeof(MPEExample) equal to the sum of the sizes of its members (in this case 20 bytes, instead of 32).\n\n","preview":"Note: This post is x86 centric. On other architectures your mileage may vary. Compiling with the -Wpadded flag on GCC/Clang or -we4820 -we4121 on MSVC, warns you when the compiler...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":16,"type":"post","title":"<b>#34</b>Fun With inotify And Hot Reloading","url":"/rival-fortress-update-34-fun-with-inotify-and-hot-reloading/index.html","game":"rival-fortress","date":"Aug 22, 2016","gameName":"Rival Fortress","content":"Back in December I implemented naive hot swappable game modules by simply checking for file updated_at timestamp each time through the game loop.\n\nThis method has worked fine for hot reloading of the game DLL, but this week I wanted to extend the system to game assets, in order to have changes to textures or shaders be reflected instantly by the game while it is running.\n\nFile change notifications\nTo extend the hot reloading capabilities of Rival Fortress I used inotify, the Linux API for monitoring file or directory events (the equivalent for Windows is FindFirstChangeNotification).\n\nThe API is straightforward and in a couple hundred lines of code I was able to plug directory monitoring in both the game as well as the asset packer.\n\nWatching asset changes and reloading\n\nThe asset packer watches the content directory and regenerate the .MPAK file whenever one of the source assets changed.\n\nThe game watches for updates to the data directory. When an existing .MPAK file is changed or a new one is added, the engine flushes all in memory assets and reloads from disk.\n\nThis watching functionality is not only useful for debugging purposes, but will also be a nice feature for modders of the game in order for them to quickly preview changes.\n\n","preview":"Back in December I implemented naive hot swappable game modules by simply checking for file updated_at timestamp each time through the game loop. This method has worked fine for hot...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":17,"type":"post","title":"<b>#33</b>Unpacking and Caching Game Assets At Runtime","url":"/rival-fortress-update-33-unpacking-and-caching-game-assets-at-runtime/index.html","game":"rival-fortress","date":"Aug 15, 2016","gameName":"Rival Fortress","content":"I modified the asset subsystem for Rival Fortress to support unpacking of compressed assets at runtime. Things like PNG images and TTF fonts will be converted to “game digestible” formats at runtime instead of having them preprocessed offline and shipped with the game.\n\nThe reason for this is that I want game content to be easily inspectable and moddable by players without too much trouble.\n\nGame and user mod content will still be distributed in the MPAK format I talked about a few weeks ago, but the game will come with an packer/unpacker executable capable of extracting .MPAK files and re-compressing them in order to facilitate modding.\n\nCaching at runtime\n\nThe first time the game encounters an .MPAK file, it parses the header looking for assets that need further preprocessing.\nAssets that are processed are packed into a new .MPAK file that is saved in the .cache folder located in the user’s “pref dir” (i.e. the OS specific folder where applications are meant to write user specific files, like save games, preferences, etc.).\n\nThe new .MPAK file has an internal reference to the parent .MPAK (there is a 1-to-1 relationship between .MPAK files) with each entry referencing the original entry. The game keeps an in memory B-tree containing asset IDs as keys and a pointer to the following data structure as values:\n\nstruct MPEPakInMemoryEntry\n{\n  MPEPakFile* File;\n  void* Data;\n  u64 Offset;\n  u32 Size;\n  MPEPakEntryType Type;\n  u16 Flags;\n};\n\nThe memory representation of the file is updated after the asset has been processed.\n\nOn demand processing\n\nNot all assets that require processing are processed on load.\nBy default assets are flagged as on-demand (using the u16 Flags above) and are lazily processed when they are required in a separate processing thread.\n\nThis means that the game treats all asset requests as asynchronous, and falls back to a default object if the asset is not found or not ready.\n\n","preview":"I modified the asset subsystem for Rival Fortress to support unpacking of compressed assets at runtime. Things like PNG images and TTF fonts will be converted to “game digestible” formats...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":18,"type":"post","title":"<b>#32</b>ALSA For Linux Game Sound","url":"/rival-fortress-update-32-alsa-for-linux-game-sound/index.html","game":"rival-fortress","date":"Aug 8, 2016","gameName":"Rival Fortress","content":"This week I started working on the audio subsystem for Rival Fortress.\n\nI’m not using FMOD, OpenAL, or any other middleware to output game sound. As with the rest of the engine, I’m trying to build most things from the ground up.\n\nThe sound APIs I’m using are: DirectSound on Windows, CoreAudio on Mac and ASLA on Linux.\n\nStarting out with ALSA\n\nMy main development platform is Linux, so I started with ALSA.\n\nThe official documentation is lacking, considering ALSA has been around for more than ten years, but fortunately the examples provided are good enough to show you how to string together the half-a-billion function calls required to set-up audio playback.\n\nThere is a lot of trial and error involved if you are looking for the ‘just-right’ playback settings.\n\nEven though ALSA has been part of the kernel for a long time, I decided not to link with libasound directly, as I’ve read many reports of version incompatibility between distributions. I’m dlopen-ing at runtime and loading in just the required function pointers.\n\nIf anything fails during initialization at runtime, the subsystem is disabled and no audio is reproduced. For most games the audio subsystem is optional, the game should be able to run even without it.\n\nThe ALSA API\n\nThe ALSA API is pretty chatty: a full playback-only initialization sequence requires almost thirty(!) function calls, all of which must be guarded against failure. Take a look at the example pcm playback to see what I’m talking about.\n\nTo keep latency low, I decided to use blocking playback with very small buffers. This requires a separate thread for audio playback, complicating the plumbing between the game and the audio subsystem, but in my current implementation I’m able to achieve very low latency levels.\n\n","preview":"This week I started working on the audio subsystem for Rival Fortress. I’m not using FMOD, OpenAL, or any other middleware to output game sound. As with the rest of...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":19,"type":"post","title":"<b>#31</b>Generating Game Configuration","url":"/rival-fortress-update-31-generating-game-configuration/index.html","game":"rival-fortress","date":"Aug 1, 2016","gameName":"Rival Fortress","content":"This week I extended Rival Fortress’s Meta reflection system to generate ‘rich’ overridable #define preprocessor directives as well as INI configuration parsing/writing.\n\nAs I explained when I first introduced the Meta reflection system, being able to generate automatically repetitive code is a huge time saver and cuts down on copy-paste type bugs.\n\nReplacing #defines\n\nI tend to use a lot of #define preprocessor directive, especially for default values and engine settings. Another usage pattern that I often use is to define minimum and maximum values along with defaults, like so:\n\n#define MPE_WINDOW_WIDTH 1600\n#define MPE_WINDOW_WIDTH_MIN 640\n#define MPE_WINDOW_HEIGHT 900\n#define MPE_WINDOW_HEIGHT_MIN 480\n\nNo suffix is the default, _MIN and _MAX suffixes are for minimum and maximum.\n\nIn order to clean up and make defines overridable, I replaced #defines with the following:\n\nMDEFINE(MPE_WINDOW_WIDTH, 1600, Min: 640);\nMDEFINE(MPE_WINDOW_HEIGHT, 900, Min: 480);\nMDEFINE(MPE_RESOLUTION_SCALE, 1.0f, Min: 0.1f, Max: 2.0f);\n\nThis generates the equivalent #define directives, each guarded by an #ifndef, so default engine values can be easily overrided by gamecode by defining the preprocessor directives before the .h is included.\n\nGenerating the Config struct\n\nI also went ahead and offloaded the generation of the config object to the meta reflection system. So, from the following snippet:\n\nMCONFIG(WindowWidth, MPE_WINDOW_WIDTH,\n        Type: i32, Section:\"Engine\",\n        Min: MPE_WINDOW_WIDTH_MIN,\n        Comment: \"Viewport width in pixels. This value excludes OS window chrome\")\n\nMCONFIG(WindowHeight, MPE_WINDOW_HEIGHT,\n        Type: i32, Section:\"Engine\",\n        Min: MPE_WINDOW_HEIGHT_MIN,\n        Comment: \"Viewport height in pixels. This value excludes OS window chrome\")\n\nThe following code is generated:\n\nstruct MPEConfig\n{\n  i32 Engine_WindowWidth = MPE_WINDOW_WIDTH;\n  i32 Engine_WindowHeight = MPE_WINDOW_HEIGHT;\n  //...\n};\n\nThis takes advantage of C++11’s brace-or-equals initializer, and generates the code for loading and writing from an INI file from the configuration object, by enforcing specified minimum and maximums.\n\n","preview":"This week I extended Rival Fortress’s Meta reflection system to generate ‘rich’ overridable #define preprocessor directives as well as INI configuration parsing/writing. As I explained when I first introduced the...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":20,"type":"post","title":"<b>#30</b>Bye Bye CMake","url":"/rival-fortress-update-30-bye-bye-cmake/index.html","game":"rival-fortress","date":"Jul 25, 2016","gameName":"Rival Fortress","content":"In the past months working on Rival Fortress I found myself having to spend an unreasonable amount of time fussing with CMake build scripts.\n\nDon’t get me wrong, I like CMake.\n\nI think it’s an excellent tool if you have to manage complex build systems that have to work on multiple platforms and multiple toolchains. It abstracts away details of the build tool with a nice DSL that truly makes builds easier.\n\nUnfortunately it can also make you waste a lot of time, especially if you are trying to do something that’s outside the standard usage pattern.\n\nMy bad experiences with CMake\n\nNASM\nBack in December I wrote about how to make CMake behave nicely with NASM. I remember wasting quite some time digging through CMake’s source trying to figure out a solution on how to have CMake detect NASM correctly. This has since been fixed in recent versions of CMake.\n\nCustom preprocessor\nWhen I implemented the engine’s Meta reflection system I had to hack together a reasonably complicated solution in order to have my custom preprocessor run before the normal build, while also tracking generated files. Something that really should be trivial to implement.\n\nClang-cl\nRecently I had to dig into CMake’s source once again, trying to figure out how to make it recognize Clang/C2 with Microsoft Codegen. I wasted a couple of days trying to get it pass the correct build flags, and stop it from detecting MSVC instead of Clang. In the end I ended up with forking the CMake repo and change the hard-coded scripts to make it do what I needed.\n\nCMakeLists.txt spam\n\nThis is more of a pet peeve of mine, but I really hate the proliferation CMakeLists.txt files. I know that I can easily stuff all my build directives into one “master” CMakeLists.txt, but CMake best practices dictate that each logical build unit should be governed by its own CMakeLists.txt. I find this makes builds hard to modify as you have to jump back and forth between multiple files just to figure out what’s going on.\n\nBack to the basics\nYesterday I nuked CMake and rewrote the build system in good ol’ GNU Make.\n\nI’m now down to one Makefile of a couple hundred lines of code, instead of seven CMakeLists.txt.\n\nThe build system is able to:\n\n\n  output five build targets:\n    \n      Meta reflection preprocessor\n      Asset packer\n      Game server\n      Game client\n      Game DLL for hot reloading\n    \n  \n  native compile on Linux and Mac using Clang and on Windows using Clang-cl\n  cross compile to Windows and Mac (from Linux) for 64 and 32 bits\n  generate HTML game documentation from Markdown files in the /docs folders\n  pack assets when out of date or modified\n  build and runs the preprocessor, correctly tracking generated files\n  assemble .asm files using NASM\n\n\n","preview":"In the past months working on Rival Fortress I found myself having to spend an unreasonable amount of time fussing with CMake build scripts. Don’t get me wrong, I like...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":21,"type":"post","title":"<b>#29</b>Extracting The Engine","url":"/rival-fortress-update-29-extracting-the-engine/index.html","game":"rival-fortress","date":"Jul 18, 2016","gameName":"Rival Fortress","content":"Engine work for Rival Fortress is coming coming to a close. This weekend I decided to give it a test run with a simple prototype in order to get a feel how the API was shaping out.\n\nWhile I was at it I also extracted the engine into a separate Git repository by using Git subtrees.\n\nGit Subtrees\n\nGit subtrees are a simple way to both split a subdirectory of an existing repository into a separate repository and include an external repository within your main repository.\n\nI use subtrees to extract reusable components into libraries from projects I’m working on. In Rival Fortress’s case, the directory tree was structured like so:\n\n  root\n   - engine\n     - game\n     - platform\n     - generated\n     - libs\n   - game\n     - libs\n\n\nAs you can see all engine code is contained in the engine subdirectory, so it was easy to pull out into a separate repository while keeping all commit history relative to the subdirectory.\n\nYou can find an excellent introduction to subtrees, with its Pros and Cons, in Atlassian’s blog post The power of Git subtree, as well as the official man page.\n\nConvention over configuration\n\nI’m a big fan of convention over configuration, and this is reflected by the way I structure engine and game code.\n\nThe engine expects certain files to be named in a specific way, as well as the folder structure to follow the one outlined above.\nI find that this makes it easy to bootstrap projects as well as giving the user of the engine/framework smarter defaults.\n\n","preview":"Engine work for Rival Fortress is coming coming to a close. This weekend I decided to give it a test run with a simple prototype in order to get a...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":22,"type":"post","title":"<b>#28</b>Code Cleanup","url":"/rival-fortress-update-28-cleanup/index.html","game":"rival-fortress","date":"Jul 13, 2016","gameName":"Rival Fortress","content":"This week I upgraded my main development PC and after a fresh reinstall of the OS I decided to do some spring cleaning.\n\nCodebase cleanup\nSince I recently upgraded Clang from 3.7 to 3.8, I tried compiling Rival Fortress with -Weverything enabled to see if they introduced new useful warnings.\n\nMany of the diagnostic warnings that are enabled with -Weverything not really useful, but I find that it’s still a useful flag to enable every once in a while, especially after upgrading compiler version.\n\nToolchain cleanup\nI finally abandoned GCC and MSVC in favor of Clang for all platforms as a frontend compiler. Previously I was using GCC when cross-compiling on Linux and Mac, and MSVC on Windows, but keeping compiler flags in sync was becoming too error prone. I now use Clang as frontend and LLVM or GNU binutils as linker/assemblers.\n\nAs a sweet side-effect, the project’s CMake scripts are much simpler too, with a lot less branching and compiler special casing.\n\nArmy knife cleanup\nI also did some cleanup on the shell script that I use for various project tasks. I’ve simplified it quite a bit, removing the compiler switching as well as code paths that I don’t use anymore.\n\nI hope that when Windows 10’s Bash support finally arrives I’ll be able to drop Cygwin and use the script “natively” on Windows too.\n\n","preview":"This week I upgraded my main development PC and after a fresh reinstall of the OS I decided to do some spring cleaning. Codebase cleanup Since I recently upgraded Clang...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":23,"type":"post","title":"<b>#27</b>Ways to Compile with Clang on Windows","url":"/rival-fortress-update-27-compiling-with-clang-on-windows/index.html","game":"rival-fortress","date":"Jul 7, 2016","gameName":"Rival Fortress","content":"Clang is my compiler of choice as I found it to be the fastest for development and it works on all desktop platforms.\n\nIn this post I’ll talk about how you can setup Clang on Windows without having to cross-compile from Mingw or Cygwin.\n\nFlavors of Clang on Windows\n\nThere are currently two flavors of Clang that work on Windows: vanilla LLVM Clang, and Clang/C2 with Microsoft Codegen.\n\nLLVM Clang is, at the time of this writing, mostly feature complete but is not able to generate PDB debugging information. It comes with two executables: clang.exe and clang-cl.exe. The former supports normal Clang-style command-line options, while the latter supports MSVC-style command-line options.\n\nClang with Microsoft Codegen, uses the Clang frontend and Microsoft’s MSVC backend to generate machine code, so it can output PDB files. It can be installed as part of Visual Studio 2015 and can be uses from the IDE or command-line.\n\nUsing Clang with GDB on Windows\n\nIn order to make Clang emit DWARF debug symbols that GDB understands, you have to use the LLVM linker so you the full LLVM installation.\n\nThe following line will compile and link an executable that can be debugged on GDB:\n\nclang.exe -O0 -gdwarf -c test.cpp -o test.obj &amp;&amp; lld-link -debug test.obj\n\nUsing Clang with Visual Studio\n\nUsing Clang with Visual Studio is straightforward if you use the version that comes bundled width the IDE. \nTo enable it follow the steps described in the official blog post. I personally haven’t tried this, as I don’t use Visual Studio.\n\nUsing Clang with CMake and Ninja\n\nMy development setup relies on CMake and Ninja, but when it came to setting up Clang on Windows I had to hack around quite a bit to get it to work.\n\nThe main problem I had to wrestle with was that CMake kept incorrectly detecting MSVC no matter what flags I set.\n\nThe hackish solution I found that works with version 3.6.0 is to use the following command:\n\ncmake -H. -G Ninja -Bbuild -DCMAKE_C_FLAGS=TRUE -DCMAKE_CXX_FLAGS=TRUE -DCMAKE_C_COMPILER=\"C:/Program Files/LLVM/bin/clang.exe\" -DCMAKE_CXX_COMPILER=\"C:/Program Files/LLVM/bin/clang.exe\" -DCMAKE_LINKER=\"C:/Program Files/LLVM/bin/lld-link.exe\"\n\nAs you can notice I have to force the C and CXX flags to TRUE. This seems to be the only way stop CMake from detecting MSVC.\n\n","preview":"Clang is my compiler of choice as I found it to be the fastest for development and it works on all desktop platforms. In this post I’ll talk about how...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":24,"type":"post","title":"<b>#26</b>More About Game PAK files","url":"/rival-fortress-update-26-more-about-game-pak-files/index.html","game":"rival-fortress","date":"Jun 27, 2016","gameName":"Rival Fortress","content":"Last week I talked about the new binary asset file format used by Rival Fortress.\nThis week I’ll talk more about PAK files in general, as in the previous post I didn’t explain why I chose the “PAK” approach for game assets.\n\nThe naive approach\nA common approach to game asset deployment is to keep all files in a plain directory structure in their original file format (i.e. images as JPG/PNG/TGA, sounds as WAV/OGG, meshes as FBX/OBJ).\nMany games do this because assets become easy to manage and patch, and become discoverable and editable by modders.\n\nThe disadvantage is that the game has to do more work at runtime. Some of the issues are:\n\n\n  having to pay the I/O overhead of having to open hundreds/thousands of file handles on each run\n  having to convert compressed image/sound formats to something the GPU/sound card can handle\n  having to build texture atlases or bitmap fonts\n  having to build vertex/index buffers from meshes\n\n\nThe better, but more laborious approach\n\nThe approach I like involves using some sort of PAK file. PAKs are resource bundles that are usually game dependent and can range from a simple uncompressed tarball-like blobs, to more complex containers with support for compression and streaming.\n\nPAK files are, in my opinion, superior to the naive approach as they allow games to pre-process each asset into a format that is better suited for runtime use.\n\nFor example, the MPAK file format that I described in the previous post apply the following optimizations:\n\n\n  images are converted to raw bitmaps or DXTC compressed bitmaps that are GPU friendly\n  meshes are converted to vertex/index buffers\n  texture groups are combined into texture atlases\n  bitmap fonts are generated with drop-shadow and outlines baked into separate channels\n  material parameters are parsed and validated\n  shaders are validated and minified\n  sounds are converted to WAV\n\n\nThe obvious disadvantage of PAKs is the required preprocessing pipeline, that has various degrees of complexity based on how much the source assets are optimized into game-friendly formats.\n\nPatching game PAK files\n\nApplying asset updates to games that use PAK files can be tricky.\n\nThe approach I chose is to allow newer PAKs to override assets specified in other PAK files. Each asset in a PAK has unique ID (calculated as the hash of the asset name), and when two assets have conflicting IDs, the one contained in the most recent PAK is chosen.\n\n","preview":"Last week I talked about the new binary asset file format used by Rival Fortress. This week I’ll talk more about PAK files in general, as in the previous post...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":25,"type":"post","title":"<b>#25</b>Game MPAK file format","url":"/rival-fortress-update-25-game-mpak-file-format/index.html","game":"rival-fortress","date":"Jun 20, 2016","gameName":"Rival Fortress","content":"This week I updated the storage file format used in Rival Fortress. The previous file format was a quick implementation I came up with while still figuring out what was needed for the engine.\nNow that most of the engine functionality is fleshed out, I decided to revise the file format to better fit the engine’s needs.\n\nAbout MPAK\n\nMPAK (Metric PAK) is a generalized binary file format optimized for disk streaming and network transmission. It is currently used to store:\n\n\n  static game assets (e.g. meshes, textures, shaders)\n  runtime data (e.g. save games, profile data)\n  user generated content (e.g. mod logic and assets)\n\n\nThe format also supports versioning and basic overwriting of previous assets: the engine at runtime loads all MPAKs and resolves any conflicting entries by keeping only the most recent one. This way mod authors can overwrite engine content by distributing custom MPAKs.\n\nFile structure\n\nMPAKs have a metadata preamble that contain:\n\n\n  A header, with a file identifier, version flags and section count;\n  A list of sections, describing the categories, storage type and count of entries to expect in the file;\n  A list of entries, describing type, size, and offset of each entry.\n\n\nByte[12] Identifier\nUInt64 Timestamp\nUInt32 Endianness\nUInt32 Version\nUInt32 Flags\nUInt32 SectionCount\n\nfor SectionIndex to SectionCount\n  UInt64 SectionOffset\n  UInt64 SectionSize\n  UInt32 SectionType\n  UInt32 SectionFlags\n  UInt32 SectionEntryCount\n  UInt32 SectionMetadataSize\nend\n\nfor EntryIndex to SectionEntryCount\n  UInt64 EntryOffset\n  UInt64 EntrySize\n  UInt32 EntryType\n  UInt32 EntryNameIndex\n  UInt32 EntryID\nend\n\nAll the metadata about the file is contained in the first bytes of the file, right after the header. This means that the engine can quickly parse the metadata to obtain the information needed in order to build the correct representation of the file entries, and resolve conflicts.\n\nAfter the metadata has been parsed the engine can proceed to make the necessary allocations and load high priority data. Files containing entries that are not needed right away are memory-mapped in order to lazy-load large data blobs on demand.\n\nSections, that group entries together, are sort of like categories and represent an homogeneous list of items, like meshes, textures or sounds. This grouping by sections is a convenience feature to facilitate parsing of similar data, like shaders or LUA scripts, that can easily fit into memory without having to random access around the file.\nData blobs for each section are stored sequentially and come after the last Entry in the metadata part of the file, at the 64 bit offsets specified by EntryOffset.\n\nNested formats\n\nThe MPAK file format specifies only the type, size and offset of each entry, not how it is stored. This allows the flexibility of treating different data types independently. For example: shaders are stored as LZ4 compressed text, while meshes are stored directly as vertex and index buffers.\nThe code in charge of writing/reading each section decided how to store the data.\n\n","preview":"This week I updated the storage file format used in Rival Fortress. The previous file format was a quick implementation I came up with while still figuring out what was...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":26,"type":"post","title":"<b>#24</b>Minimal Perfect Hashing for Game Assets","url":"/rival-fortress-update-24-minimal-perfect-hash-for-game-assets/index.html","game":"rival-fortress","date":"Jun 13, 2016","gameName":"Rival Fortress","content":"Perfect hash functions are the holy grail of hashing functions.\nThey guarantee no key collisions and work really well when dealing with data that is either static, where all keys are known in advance, or rarely changing.\n\nMinimal perfect hash functions (MPHF) are even better. They guarantee 100% load factor, so your hash tables will contain only one entry for each key, and no empty slots.\n\nHash tables that use MPHF are more memory efficient and have generally faster retrieval times; they also have excellent cache locality by removing cache misses that arise due to collision resolution schemes required for traditional hash tables.\n\nThe downside is that MPHF-backed hash tables are more costly to generate and trickier to implement, as they require more setup than most hash table implementations. This makes them impractical for dynamic data set like the ones you usually find in games.\n\nMPHF for game asset lookups\n\nFor the asset system used by Rival Fortress I decided to use MPHF-backed hash tables for asset and font kerning lookups.\n\nThe reason for adding hash table lookups to assets, instead of just indexing them statically, is because of the engine’s modding capabilities.\nUsers will be able to add custom assets and refer to them through LUA, so internally they have to be stored in hash tables.\n\nFortunately, both engine and mod assets are preprocessed offline, so I can leverage MPHF without having to pay the runtime cost.\n\nAssets are referenced through an unsigned 32-bit integer generated by the preprocessor. The key is used to calculate the intermediate MPHF lookup table and this, in turn, is used to populate the final assets hash table that is then stored in the PAK file.\n\nThe hash tables, generated using an implementation based on the Compress, Hash, and Displace algorithm. I’m using a load factor of 100%, and lambda values of 1 and 4 for assets and for font kerning data.\n\nAdditional resources\n\nI won’t share any example code as my implementation is tightly coupled with the asset preprocessor, but I’ll point you in the direction of some open source implementations:\n\n\n  (LGPL/MPL) http://cmph.sourceforge.net/\n  (GPL) http://www.gnu.org/software/gperf\n  (Public domain) http://burtleburtle.net/bob/hash/perfect.html\n  (MIT) https://github.com/wahern/phf\n\n\n","preview":"Perfect hash functions are the holy grail of hashing functions. They guarantee no key collisions and work really well when dealing with data that is either static, where all keys...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":27,"type":"post","title":"<b>#23</b>Custom Tools for Game Development","url":"/rival-fortress-update-23-custom-tools-for-game-development/index.html","game":"rival-fortress","date":"Jun 6, 2016","gameName":"Rival Fortress","content":"There’s an excellent chapter in Game Engine Architecture about custom tools that are often developed to aid in the making and debugging of a game engine.\n\nToday I’ll talk about the ones I developed for Metric Panda Engine, the game engine that powers Rival Fortress.\n\nThe Shell Swiss Army Knife\n\nI spend most of my development time in the terminal, and the way I interact with the game, engine or other standalone tools is through a multi-purpose shell script.\n\nThis is what the output of the panda help command:\n\nUsage: panda &lt;command&gt; [&lt;args&gt;]\n\nbuild and target management\n   init       Initialize all platforms\n   compiler   Change current compiler\n   clean      Clean all build artifacts\n   nuke       Remove build and output folders\n\nswitch the active build to the another platform\n(*)linux      Compile for Linux\n   osx        Cross-compile for OSX\n   win        Cross-compile for Windows\n\nrunning and testing\n   game       run game\n   server     run server\n   assets     run asset preprocesor\n   meta       run meta reflector on codebase\n   test       run unit tests\n   bench      run performance benchmarks\n   log        tail game or server log\n\nrelease and deployment\n   release    Build in release mode for all platforms\n   deploy     Package and deploy release builds\n\nutility functions\n   cloc       Count lines of code\n   ctime      Build timings and statistics\n   demo       Start the game and capture video\n   duplicates Show duplicate symbols between shared libs\n\nSee panda help &lt;command&gt; for additional arguments\n\nThe script is composed of a handful of small git-style shell scripts that delegate the heavy lifting to the appropriate standalone tool or application.\n\nThe Asset Preprocessors\n\nI talked in previous posts about the asset preprocessor. It’s a collection of asset related tools that can be run as a command line utilities or directly from the editor.\n\nThe tools operate by parsing a JSON manifest file and are capable of:\n\n\n  Parsing OBJ and FBX models and converting them to vertex/index buffer streams,\n  Validating and minifying GLSL shaders and combining them into shader pool\n  Setting up material parameters and default values\n  Packing bitmap fonts into multiple texture atlases for different Unicode ranges along with other UI related textures\n  Combining and compressing textures\n  Converting sound files and packing them based on priority and/or usage order\n  Combining and validating LUA scripts\n\n\nThe Meta Reflector\n\nThe meta reflector is a preprocessor that generates all sorts of code, ranging from data structures, boilerplate code, validation and data mappings between .ini configs and runtime data. Take a look at this post for more about it.\n\nThe Game Editor\n\nLast but not least is the game editor. This is a module that can be loaded from the game as a dynamic library and allows the interaction with other tools from the GUI as well as manipulation of the game world.\nI’m still actively iterating on the editor as most of the functionality required surfaces when writing gameplay code.\n\n","preview":"There’s an excellent chapter in Game Engine Architecture about custom tools that are often developed to aid in the making and debugging of a game engine. Today I’ll talk about...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":28,"type":"post","title":"<b>#22</b>Finding Duplicate Static Symbols in Shared Libraries","url":"/rival-fortress-update-22-finding-duplicate-static-symbols-in-shared-libraries/index.html","game":"rival-fortress","date":"May 30, 2016","gameName":"Rival Fortress","content":"Sometimes it is useful to split code into shared libraries that get loaded by the main executable depending on runtime requirements.\n\nFor example, the current development version of Rival Fortress is structured like so:\n\n\n\n\n\n  The Launcher is the main executable that contains shared data types, interacts with the OS and abstracts away any platform related functionality needed by the shared libraries.\n  The Game is a shared library that contains all engine and game code. Keeping it in a library makes it easy to hot reload it without having to restart the game.\n  The Networking library is loaded when the player initiates a multiplayer game or when the game is started as a headless dedicated server.\n  The Editor is also a shared library with the code for the gameplay editor. It can be loaded and unloaded by pressing F11 while the game is running.\n\n\nDuplicate static functions\n\nPartitioning code across multiple modules can cause logic defined in static functions to be duplicated silently and, while it will compile just fine and won’t cause any problems at runtime, it will unnecessarily bloat the size of the .dll/.dynlib/.so.\nDuplicate functions can also cause subtle bugs when shared libraries are built with different versions of the code, but this won’t happen if you build all your modules when common code changes.\n\nFor example, imagine you have the following function defined in utility.c that gets included in both the Game and Editor shared libraries.\n\nstatic int ComplexOperation(int Value)\n{\n  return Value * 2;\n}\n\nEach library will get a copy of the function and because it’s defined as static you will not get any compiler warning about the duplication.\n\nTo see for yourself you can the nm tool on Linux and OSX or dumpbin on Windows with the /SYMBOLS flag. \nBoth tools will show you the symbols table exported by the library or executable. This is what nm outputs when run on OSX:\n\n0000000000000fa0 t _ComplexOperation\n\nFinding duplicate symbols\n\nIf you reverse diff the output of nm or dumpbin of two libraries you will find duplicate symbols.\n\nBefore you do that, though, you need to massage the output a bit. On *nix based systems, or by using bash.exe, you can use the following command:\n\n$ nm sharedlib.so | c++filt | cut -d ' ' -f 3-99 | sort | uniq\n\n\n  nm returns the list of symbols in the library\n    \n      Omit this if you are using bash.exe on Windows 10, and cat the output of dumpbin\n    \n  \n  c++filt demangles any C++ symbols. You can read more about it on the man page,\n  cut trims the first two tokens of each line that contain the memory location of the symbol, as it will more than likely differ for each library,\n  sort sorts the symbols in alphabetical order (instead of being sorted in ascending memory location order)\n  uniq removes any duplicate symbols (this is useful when deadling with C++ code)\n\n\nYou can optionally filter the results using grep if you use common prefixes for all your functions, as this will remove all the noise generated by compiler defined symbols.\n\nUse the comm command to reverse diff the outputs like so:\n\n$ comm -12 output1.txt output2.txt\n\nNow that you know what symbols are duplicated it’s up to you decide how to best clean things up.\n\n","preview":"Sometimes it is useful to split code into shared libraries that get loaded by the main executable depending on runtime requirements. For example, the current development version of Rival Fortress...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":29,"type":"post","title":"<b>#21</b>Web Stuff","url":"/rival-fortress-update-21-web-stuff/index.html","game":"rival-fortress","date":"May 25, 2016","gameName":"Rival Fortress","content":"\n\n\nNot much coding went into Rival Fortress this week as I decided to give the website a facelift. It has been a while since I dabbled in web dev stuff, so it was fun to get up to speed with how the cool kids are “left-padding”.\n\nGet ready for some buzzwords.\n\nThe web stack\n\nI’m using Jekyll to generate the website. I think it’s one of the best static generators out there. It has sensible defaults and is sufficiently fast for my needs.\n\nThe luxury of having a static website also allows for fast and simple deployments: all you need is a webserver that can serve static files like nginx or Apache.\nI’m using Github Pages, as it’s essentially just a git push to get the site online.\n\nThe asset pipeline is handled by jekyll-assets as I’m a big fan of SASS and Coffeescript. I’m also using a Ruby plugin to generate Hogan JS templates and one for sprite-factory to generate image sprites.\n\nAutomating with Gulp\n\nBuild tools like Grunt and Gulp help automate tasks like image compression, and asset minification.\n\nGulp tasks that are part of the deployment process are:\n\n\n  Autoprefixer and unused CSS selector remover\n  Javascript, JSON, CSS and HTML minification\n  Inlining of CSS stylesheets\n  Image compression using pngquant, jpegtran and optipng\n  Video encoding to MP4 and Webm using ffmpeg\n  Uploading to Amazon S3 of encoded videos\n  Pinging Google and Bing with the updated sitemap.xml\n\n\nA full deploy starting from an empty folder takes about 10 seconds. Successive deploys are in the order of 1-2 seconds thanks to Jekyll’s --incremental flag and the fact that images don’t need to be re-compressed unless changed.\n\nThis is what a full deploy looks like:\n\n\nFull website deploy with GulpRead More \n\n\nFast page load times\nIt’s easy to bloat even the simplest website by adding one too many Javascript libraries, forgetting to compress images, or embedding too many external resources.\n\nFortunately there are many tools that help us diagnose such problems, like Google’s PageSpeed Insights Webpage Test or Pingdom Website Speed Test.\n\nThe best ways to improve load times are:\n\n\n  Compress images. Tools for image optimization is an excellent resource\n  Minify and combine Javascripts and CSS files into bundles\n  Remove unused CSS\n  Inline essential CSS to render above the fold content or, for small websites, inline all your CSS\n  Combine images into sprite sheets and use icon fonts like Fontawesome\n  Use something like Turbolinks or pjax to increase responsiveness\n  Use a CDN to deliver static content or signup for CloudFlare for a fast and easy solution\n\n\nHere are the results from Google Pagespeed Insights when run on this website:\n\n\n\n","preview":"Not much coding went into Rival Fortress this week as I decided to give the website a facelift. It has been a while since I dabbled in web dev stuff,...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":30,"type":"post","title":"<b>#20</b>The C++ Subset","url":"/rival-fortress-update-20-the-c-subset/index.html","game":"rival-fortress","date":"May 16, 2016","gameName":"Rival Fortress","content":"I like to keep an eye on new developments of the C++ spec and the direction the language is moving, but in the code for Rival Fortress I don’t use most of the features that C++ has to offer.\n\nThe features I don’t like\n\nI don’t use object-oriented programming. Most of my code is written in a functional programming style, as I’m a big fan of data-oriented design.\n\nI rarely use inheritance, and if I use it, I stay away from virtual functions or deep hierarchies. I find the code to be cleaner and easier to understand when one doesn’t need to study deep class hierarchies to figure out what a piece of code is doing.\n\nI’m also not a big fan of the Standard Library as I find that most of the functionality it provides is either less performant than ad-hoc implementations or tends to hide complexity that I’d rather have out in the open.\n\nI rarely use templates as most of the problems they address can be solved with code generation as I talked about in my reflection preprocessor post. Templates also bloat compile times considerably and produce god-awful compiler error messages.\n\nI never use exceptions as I find them to be a useless performance penalty that can be easily avoided with careful coding. They also increase code complexity because of all the redundant try/catch blocks that tend to pollute codebases that use them.\n\nI don’t use RTTI as a lot of the code that would require introspection is generated by Rival Fortress’s engine preprocessor.\n\nI don’t use RAII and very rarely use object constructor/destructor pairs. I find that RAII is unnecessary when coding in a functional style.\n\nThe features I like\n\nMost of my code is C99-like, with the exception of the following features that I found useful:\n\n\n  Operator overloading: when it makes sense, like for simple vector math (i.e. addition, subtraction, scalar multiplication).\n  Function overloading: I try to use self-documenting function names, but I find that in C the lack of function overloading can force you to either use verbose or cryptic names when the same logical function needs to operate on different data types.\n  const_expr: is sometimes useful when I don’t want to go the macro route and need something to be evaluated at compile time. For example, string length and string hashing have both a runtime and a const_expr version.\n  static_assert: I find it very useful especially for sanity checks and paired with const_expr functions or for validation of meta programmed code generated by the engine’s preprocessor.\n  raw string literals: are very useful when dealing with long string. I use them very often while working on the engine preprocessor.\n  lambdas: are sometimes useful as a convenience feature, but most of the times I just use function pointers.\n\n","preview":"I like to keep an eye on new developments of the C++ spec and the direction the language is moving, but in the code for Rival Fortress I don’t use...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":31,"type":"post","title":"<b>#19</b>UDP Networking for Multiplayer","url":"/rival-fortress-update-19-reliable-udp-for-multiplayer/index.html","game":"rival-fortress","date":"May 9, 2016","gameName":"Rival Fortress","content":"This week has been dedicated to more multiplayer development for Rival Fortress.\n\nI’ve fleshed out a networking model based on the one described in the original Tribes paper with a few twists of my own.\n\nThe model is built on top of the User Datagram Protocol(UDP), a very flexible and simple protocol that, is one of the most common choices when it comes to online multiplayer games (the other being the Transmission Control Protocol(TCP)).\n\nUDP, unlike it’s “bigger brother” TCP, is an unreliable protocol, meaning that when sending a packet to a destination computer there is no guarantee or notification of delivery. This may look like a downside, but as Glenn Fiedler explains very well in his post UDP vs. TCP, UDP is the ideal protocol for most games because it provides the flexibility needed for responsive online multiplayer.\n\nIdeal packet size\n\nOptimal networking code, among other things, tends to be about cramming as much information as possible into the least possible space.\nThis is because, although you can theoretically construct UDP packets as large as 65,535 bytes, the ideal size is dependent on the Maximum transmission unit(MTU) of the Internet that is around 1500-bytes per packet.\n\nPackets larger than this will cause routers to split your packet into multiple parts (packet fragmentation), complicating things for you.\n\nOptimal Network replication\n\nPacket size constraints require a smart approach to serializing game objects for replication. You can’t just naïvely memcpy your objects into UDP datagrams and hope for the best; most of the time you will be sending bloated data over the wire, when you could have serialized only relevant bits. \nFor example sending 4 bytes for an integer that only needs 5 bits to represent it’s full range used in the game it’s rather wasteful, it may not seem like much in isolation, but it can add up pretty quickly over the course of a multiplayer session.\n\nThere are many ways to approach compact object serialization and replication, but the ideal way depends on the type of game you are building and the type of data you need to send over the wire. Take a look at the excellent Building a Game Network Protocol series for a primer on how to go about implementing your own solution.\n\nNetworking code generation\n\nFor Rival Fortress I extended the reflection system of the engine to generate most of the serialization and replication code.\n\nFor example the following snippet of code represents a message sent by the client to initiate a connection to the server:\n\nMREFLECT(NetworkMessage, Reliability=Guaranteed, Priority=High)\nstruct MPEConnectionRequestMessage\n{\n  MREFLECT(NetworkValue, Size=NameLength)\n  char Name[MPE_NETWORK_MAX_NAME_LENGTH+1];\n\n  MPEVersion Version;\n\n  MREFLECT(NetworkValue, Size=5bits)\n  u32 NameLength;\n};\n\nAs you can see, the struct is annotated with a no-op MREFLECT macro that gets parsed by the reflection preprocessor. \nIn this case the engine will generate the code to send a guaranteed packet (i.e. it will retry up to a maximum amount of times until a confirmation reply is received from the destination) with a high priority (i.e. it will prioritize this message when constructing the packet over others with lower priority).\n\nAlso, you can see that the struct members are annotated to indicate how much space they should occupy in the final UDP packet: 5 bits for the NameLength and NameLength for the Name string.\n\nEvery struct like this generates a send/receive pair of functions that handle the serialization and deserialization.\n\nThe engine tries to pool multiple messages into a single UDP packet until the packet size is reached or a timer threshold is surpassed (10 milliseconds) in order to not waste bandwidth on packet overhead.\n\n","preview":"This week has been dedicated to more multiplayer development for Rival Fortress. I’ve fleshed out a networking model based on the one described in the original Tribes paper with a...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":32,"type":"post","title":"<b>#18</b>Multiplayer Decisions","url":"/rival-fortress-update-18-multiplayer-decisions/index.html","game":"rival-fortress","date":"May 2, 2016","gameName":"Rival Fortress","content":"I’ve started working on the multiplayer code for Rival Fortress. It’s an exploratory process, as low level networking is very much new to me.\n\nI’m trying to get the simplest and dumbest possible implementation running without adding too much complexity. I’ll probably have to double-back on most of my decisions, so I don’t want to get too attached to the first working implementation.\n\nNetwork topology\nThe network topology that I’m leaning towards is client-server with a dedicated headless server executable and a built-in listen server for the standalone game.\nI’m also considering a deterministic lockstep peer-to-peer networking model, but I think that the ideal topology will emerge once the game gets more fleshed out.\n\nDedicated server\nTo get my feet wet I started working on the dedicated server. It is a command-line executable that shares all the code with the game with exception of the rendering code.\n\nThe process of adding a new build target was straightforward: it was just a matter of #ifdef-ing out all rendering code and adding a call to the server loop instead of the game loop.\nI want to build the dedicated server using the same code as the standalone game, as I think this will make it easier when I’ll implement the listen server.\n\nSerialization and replication\n\nI cobbled together support for basic replication: Plain Old Data (POD) objects get sent back and forth between the client and server using UDP. \nAs I don’t use inheritance or new in my C++ code I don’t have to worry about virtual methods or constructors/destructors, so replicating POD objects is just a simple memcpy into the network packet.\n\nI haven’t handled pointers yet, but I’ll most likely leverage the engine’s reflection preprocessor to generate code for serialization and replication of complext game objects.\n\nI’m also looking at forms of entropy encoding and other forms of data compression to reduce the amount of stuff sent over the wire. \nI implemented a floating point to half float converter that reduces 32bit floats to 16 (for position information), and a simple entropy encoder that can serialize partial structs.\nEvery serialized object has an tiny header that contains serialization information about the object as a bit flag.\n\n","preview":"I’ve started working on the multiplayer code for Rival Fortress. It’s an exploratory process, as low level networking is very much new to me. I’m trying to get the simplest...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":33,"type":"post","title":"<b>#17</b>Deferred Shading and packed Uniform Buffer Objects","url":"/rival-fortress-update-17-deferred-shading-and-packed-uniform-buffer-objects/index.html","game":"rival-fortress","date":"Apr 25, 2016","gameName":"Rival Fortress","content":"This past week I did some more work on the rendering engine for Rival Fortress by adding a deferred shading path.\n\nDeferred rendering is particularly useful when working with many dynamic lights, and since I really want to have light/dark mechanics in the game, a combination of forward and deferred shading is the right fit for the engine.\n\nI also started laying the groundwork for the post process chain as well as conditional shader compilation based on user settings and hardware capabilities.\n\nAutomatic OpenGL packed uniform layouts\nWhile working on the renderer I also extended the reflection preprocessor by adding the ability to generate OpenGL uniform buffer object metadata for both shared and packed memory layouts.\n\nThe advantage of using shared or packed comes in the form of better memory utilization, and potentially better performance (due to better memory alignment) compared to the std140 memory layout.\n\nThe downside is that you have to query uniform memory locations and strides manually for each uniform block as there are no constraints on how the driver will rearrange or pad your uniforms. This means you can’t simply memcpy your struct into the uniform buffer when you want to update it.\n\nPreprocessing struct metadata\nTo avoid the error prone process of manually having to fuss with the alignment code whenever I add or modify a uniform, I extended the engine preprocessor to look for structs annotated like the following:\n\nMREFLECT(UniformBlock, Name:\"MPECamera\")\nstruct MPECameraUniformBlock\n{\n  MPEMatrix4 ViewProjectionMatrix;\n  MPEMatrix4 InverseProjectionMatrix;\n  MPEVec4 CameraPosition;\n  MPEVec4 CameraDirection;\n  void* PackingInfo;\n  u32 Offset;\n  u32 Size;\n};\n\nThe MREFLECT annotation is a no-op macro that tells the preprocessor that it should generate code for a uniform block named MPECamera.\n\nThe preprocessor then goes ahead and generates all the boilerplate code required to query the graphics card for uniform alignment, padding, and stride of each of the members of the struct, as well as the code needed to update the uniform.\n\nThe void* points to one of many types of packing information that is determined at runtime based on how the driver decides to layout the data and is used whenever the uniform needs to be updated.\n\nSince all the code that does the dirty work is automatically generated by the preprocessor using a void* has more flexibility and less baggage than using templates or inheritance as type safety is enforced at compile time.\n\nAligning for better packing\n\nMost modern cards will pad uniform entries so that they are aligned to 16 byte boundaries when using the shared or packed memory layout.\n\nFor this reason it is often better to aggregate variables in four component vectors like vec4 or ivec4 and use swizzling to access the individual variables in the shaders. \nThat is also the reason why I chose a MPEVec4 (a four component vector) to represent camera position and direction in the previous code snippet.\n\nPooling uniform blocks in large buffers\n\nAnother useful optimization when dealing with uniform buffer objects is pooling multiple blocks into large buffer objects, similarly to how you would pool multiple meshes in VBO.\n\nFor example, in Rival Fortress the lighting, camera, and world data uniform blocks are all stored in a single buffer object, thus reducing buffer switches.\n\nAdding a path for when the ARB_buffer_storage extension is supported allows you to get a pointer that you can write into whenever you need to update your uniforms without having to do any gl calls.\nFor more information on this and other low overhead OpenGL techniques I suggest you take a look at the Steam Dev Days talk Beyond Porting: How Modern OpenGL Can Radically Reduce Driver Overhead (The slides are here).\n","preview":"This past week I did some more work on the rendering engine for Rival Fortress by adding a deferred shading path. Deferred rendering is particularly useful when working with many...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":34,"type":"post","title":"<b>#16</b>Custom memory allocators","url":"/rival-fortress-update-16-custom-memory-allocators/index.html","game":"rival-fortress","date":"Apr 18, 2016","gameName":"Rival Fortress","content":"This week I’ll briefly talk about the custom memory allocators used in the 3D engine that I’m developing for Rival Fortress.\n\nMinimizing system allocator usage\nC and C++ don’t have built in garbage collection, so it’s up to the developer to decide how and when to allocate and free memory.\n\nRelying only on the system allocator by using new or malloc for every allocation can cause performance issues, especially when trying to reduce cache misses and cache locality as allocations, even back-to-back allocations, are not guaranteed to be close in memory.\n\nA secondary, but less common, side effect is heap fragmentation: an issue that arises when the system allocator has to periodically waste cycles defragmenting memory because many small allocations and frees have caused the heap to become fragmented.\n\nCustom allocators\nCustom allocators, on the other hand, allow for much finer grained control.\nThey are usually built on top of the system allocator and work by allocating and partitioning larger memory blocks into smaller chunks requested by the application.\n\nYou can find out more about custom allocators in the excellent Game Engine Architecture by Jason Gregory.\n\nI’m not a big fan of object oriented programming and many of the features C++ has to offer, so most of the allocators that I implemented for the game engine don’t use any C++ fanciness (a part from constructor/destructors used by the ScopeAllocator).\nYou could certainly implement custom allocators by overloading the new operator and using placement new to partition out memory and sprinkling in some templating magic, but that’s not my cup of tea.\n\nAllocators used in Rival Fortress\n\nFor Rival Fortress, I allocate a large chunk of memory on start up and partition it to the various subsystems using the following allocators:\n\n\n  PushAllocator: A simple stack based allocator that, given a block of memory, partitions it out by incrementing a location in a similar manner to how the stack pointer works.\n  SlidingAllocator: Works on top of a stack allocator and grows until the parent allocator has memory. The characteristic of this allocator is that it can rewind all allocations in order to reset the allocated memory. This is useful as a “one-frame-only” allocator for temporary operations that get wiped at the end of the frame.\n  FreeableAllocator: This is one of the few allocators that can reclaim memory and repartition it. It has the capability of merging contiguous free blocks and reallocate existing pointers.\n  ScopeAllocator: A temporary allocator that discards any allocations and rewinds the end of the scope.\n  ArrayAllocator: Used for growing lists of lists.\n  DoubleEndStackAllocator: Similar to the stack allocator, but can grow from both the head or the tail of the memory block.\n  ObjectPool: A simple bounded pool of struct that can get recycled by last usage time. This is used in the engine to retire old rendering “chunks” and replace them with new ones without needing to allocate.\n  StringPool: A string interner used for all strings used by the game and engine that allows fast lookups through hashes and string recycling.\n\n","preview":"This week I’ll briefly talk about the custom memory allocators used in the 3D engine that I’m developing for Rival Fortress. Minimizing system allocator usage C and C++ don’t have...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":35,"type":"post","title":"<b>#15</b>Video recording for game development","url":"/rival-fortress-update-15-video-recording-for-game-development/index.html","game":"rival-fortress","date":"Apr 11, 2016","gameName":"Rival Fortress","content":"Having a way to capture game video footage is essential for any Indie game developer.\n\nIt can allow you to:\n\n\n  Store videos for visual comparisions of different builds (useful when testing)\n  Capture gameplay demos to share online\n  Have a video of the last few seconds before a crash\n\n\nThere are many software packages out there that allow you to capture game footage, like FRAPS, Camtasia or OBS.\n\nIn this post I’ll talk about how to easily roll your own custom solution in order to have much more power and flexibility over how and when you capture.\n\nThe building blocks of screen capture\n\nFFmpeg is an open-source cross-platform “swiss army knife” of video and audio manipulation. It’s a must have if you are doing any kind of video or audio work (which you are if you are an indie dev).\n\nApitrace is a set of tools that can record and playback OpenGL and Direct3D calls made by an application with relatively little overhead.\nApart from being an excellent debugging tool it may be repurposed as game video capturer with a little bit of work on your part.\n\nCapturing by piping frames to FFmpeg\n\nThe most powerful way to do screen capturing of your game is to stream raw pixel data directly from the backbuffer of your game to disk.\n\nThis can be done easily in OpenGL with a call to glReadPixels or in Direct3D with CopySubresourceRegion.\n\nThe problem of writing RGB pixel data to disk is that the files produced are huge and not really practical if you want to record long sessions.\n\nA better approach is to pipe the data directly into FFmpeg as described by Miles Macklin in his post Real-Time Video Capture with FFmpeg.\nThis approach trades off disk I/O with a bit of CPU overhead required by FFmpeg to do the encoding. In my experience the overhead is perfectly acceptable and on par with FRAPS, that to my knowledge is the most lightweight capturing solution.\n\nIn his post he uses GL_RGBA as output format, but I suggest you use GL_RGB, as this will reduce the bandwidth required by 25% with no quality loss.\nAlso if you are on Unix based system you have to use popen and pclose instead of _popen and _pclose.\n\nCapturing with apitrace\n\nAn alternative method of low overhead capturing is with apitrace. I’ve only tried this on Linux and OSX, so your mileage may vary if you are on Windows.\n\nAs explained in the documentation you can use the following commands to record to video:\n\n\n  Capture a trace of your game by running it like so:\n\n\napitrace trace game-executable\n\n\n  From the command line run:\n\n\napitrace dump-images -o - game-executable.trace \\\n| ffmpeg -r 30 -f image2pipe -vcodec ppm -i pipe: -vcodec mpeg4 -y output.mp4\n\nA little more work is required to “cut” the video to only the part that interest you, either using the apitrace trim command, or by editing the video in an external software.\n\n","preview":"Having a way to capture game video footage is essential for any Indie game developer. It can allow you to: Store videos for visual comparisions of different builds (useful when...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":36,"type":"post","title":"<b>#14</b>Micro-profiling game code","url":"/rival-fortress-update-14-micro-profiling-game-code/index.html","game":"rival-fortress","date":"Apr 4, 2016","gameName":"Rival Fortress","content":"Most game programmers like to have quick access to graphical performance charts in order to keep an eye on potential performance bottlenecks while developing or testing the game.\n\nEvery off-the-shelf game engine offers some kind of profiling HUD that you can enable while developing and, if you are rolling your own engine, there are many open source libraries you can quickly plug into your game (I suggest taking a look at Sean Barret’s IProf if you want something lightweight).\n\nWhen you find a bottleneck the right way to optimize it is not always clear right away, and it often comes down to trial and error.\n\nThe approach I tend to use when I’m doing a performance tuning pass over the codebase is to isolate problem spots into small, self-contained, snippets of code and profile them in isolation using Micro-benchmarking.\n\nMicro-benchmarking is a very useful tool for performance tuning algorithms or other self-contained code.\n\nI find that being able to quickly iterate over the piece of code and benchmarking it against the original implementation is often eye-opening. \nModern CPUs are complex beasts, and sometimes what we may think is the most optimal implementation may not actually be as fast as a maybe naive  implementation.\n\nThe Good of micro-benchmarking\n\nMicro-benchmarking is perfect for exploratory-type coding.\n\nAs an example, I recently needed to tune the string hashing function used by the asset system of Rival Fortress. \nMost string hashing is done offline, but during runtime the game has to hash strings coming in from Lua game mods.\n\nAfter trying several well known hashing algorithms, I hacked together a custom version of the MurmurHash that gave me a significantly better performance characteristic on the dataset used by the game.\n\nThe Bad of micro-benchmarking\nMicro-benchmarking isn’t so good at giving you the big picture.\n\nFactors that come into play when many subsystems are interacting, like cache locality and memory access, often get lost or skewed when you focus in on a small piece of code.\n\nSo it’s important to keep in the back of your mind the context in which the code you are trying to optimize will be executing.\n\nGoogle benchmark\nMy go-to library for micro-benchmarking is Google benchmark. Google benchmark is an open source library written in C++ that allows you to quickly run benchmarks over snippets of C/C++ code. Take a look at the Github repository examples.\n\nThe excellent talk at CppCon 2015 by Chandler Carruth Tuning C++: Benchmarks, and CPUs, and Compilers! goes into some detail on how to use Google benchmark understand profiler output and how to use perf on Linux to dig deeper into optimized C++ executables.\n\n","preview":"Most game programmers like to have quick access to graphical performance charts in order to keep an eye on potential performance bottlenecks while developing or testing the game. Every off-the-shelf...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":37,"type":"post","title":"<b>#13</b>Text formatting and Unicode","url":"/rival-fortress-update-13-text-formatting/index.html","game":"rival-fortress","date":"Mar 28, 2016","gameName":"Rival Fortress","content":"A while ago I talked about the font rendering used by Rival Fortress.\n\nThis past week I added more functionality to the text rendering subsystem in the form of better text formatting and Complex Text Layout.\n\nRival Fortress won’t need a complex text rendering engine, but it will require the ability to add formatting and styling.\n\nText formatting\n\nThe formatting needs of the engine are basic horizontal and vertical alignments, wrapping and scrolling within a parent container.\n\nThese are thing that most game developers give for granted, as they are built in every major off the shelf game engine, but when you are rolling your own tech you need to wrestle with implementation details.\n\nI’m still working on interactive text similar to text links in World of Warcraft:\n\n\n\nInteractive text is useful when you want the user to drill down on a particular topic or game mechanic, either by showing a tooltip or by opening a related user interface element.\n\nI’ve also started working on support for CJK and Bi-directional text.\n\n","preview":"A while ago I talked about the font rendering used by Rival Fortress. This past week I added more functionality to the text rendering subsystem in the form of better...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":38,"type":"post","title":"<b>#12</b>Game Editor","url":"/rival-fortress-update-12-game-editor/index.html","game":"rival-fortress","date":"Mar 22, 2016","gameName":"Rival Fortress","content":"This week I started working on the game editor for Rival Fortress.\n\nIn a way similar to how Unreal Engine does it, I chose to implement the game editor as DLL module that gets loaded by the game executable on demand, instead of writing a separate application that edits game data.\n\nI think this is the most sensible approach as I intend to ship the editor with the game to allow modders to easily and quickly make tweaks and test their mods without having to open a separate application.\n\nThe dual platform layer\n\nArchitecturally I want to have a clear separation between platform specific code and engine/game code, as this make it much easier to port the game to new platforms.\n\nSince the editor needs to interact much more with the platform (mostly in the form of file/directory IO) than the game, I decided to split the platform layer in two: Game platform and Editor platform.\n\nThe game platform exposes functions for basic file I/O (for reading and writing of config, save games and assets), rendering, user input and audio.\n\nThe editor platform is a superset of the game platform, and exposes many more fine grain I/O related functions that are essential for managing temporary files/directories, monitoring file changes, deleting and moving around files, as well as packaging game assets. All this functionality is loaded into memory only if the editor is active.\n\nPassing platform functions through DLL boundaries\n\nThe editor is loaded as a dynamically linked library and to avoid duplicating functionality, it receives a struct containing function pointers to the platform layer, the engine and game contexts.\n\nThis facilitates the modularization of editor components that can easily reuse engine, game and platform functionality.\n\n","preview":"This week I started working on the game editor for Rival Fortress. In a way similar to how Unreal Engine does it, I chose to implement the game editor as...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":39,"type":"post","title":"<b>#11</b>Cross compiling for Three Platforms","url":"/rival-fortress-update-11-cross-compiling-for-three-platforms/index.html","game":"rival-fortress","date":"Mar 15, 2016","gameName":"Rival Fortress","content":"I’ve moved permanently to Linux as my development platform. I’m in love! Linux is giving me even more freedom from clutter and OS annoyances than what OSX was giving me. How did I ever get by without a tiling window manager!\n\nFanboyism aside, this week I finally finished the cross compiling setup that I started working on a while back.\n\nWhenever I push commits to the Github repository, an automated build triggers for the three platforms that Rival Fortress will ship on: Windows (32/64bits), Linux (32/64bits) and OSX(64bits).\n\nThe build “server” is Mac Mini running a bare bones installation of Arch Linux.\n\nCross compilation process\n\nThe cross compilation process is handled by a simple bash script.\nThe setup step, that is run only once after a clean git clone, initializes Cmake for the 5 “platforms” like so:\n\n# 64 bit builds\nif [ ! -d build/linux64 ]; then\n  cmake -H. -Bbuild/linux64 -G Ninja -DCMAKE_BUILD_TYPE=Debug\nfi\n\nif [ ! -d build/osx ]; then\n  cmake -H. -Bbuild/osx -G Ninja -DCMAKE_BUILD_TYPE=Debug -DCMAKE_TOOLCHAIN_FILE=cmake/x86_64-osx.cmake\nfi\n\nif [ ! -d build/win64 ]; then\n  cmake -H. -Bbuild/win64 -G Ninja -DCMAKE_BUILD_TYPE=Debug -DCMAKE_TOOLCHAIN_FILE=cmake/x86_64-w64-mingw32.cmake\nfi\n\n\n# 32 bit builds\nif [ ! -d build/linux32 ]; then\n  CFLAGS=-m32 CXXFLAGS=-m32 cmake -H. -Bbuild/linux32 -G Ninja -DCMAKE_BUILD_TYPE=Debug -DCMAKE_TOOLCHAIN_FILE=cmake/i686-linux.cmake\nfi\n\nif [ ! -d build/win32 ]; then\n  cmake -H. -Bbuild/win32 -G Ninja -DCMAKE_BUILD_TYPE=Debug -DCMAKE_TOOLCHAIN_FILE=cmake/i686-w64-mingw32.cmake\nfi\n\nEach build, a part from the 64 bit Linux, has a toolchain file associated with it that specifies the compiler to use and the path to libraries and headers.\n\nThe 64 bit Linux build doesn’t need a toolchain file since the system is 64 bit and is configured to build by default using Clang 3.8.\n\nThe 64 bit Linux also runs first as it is the only build that will run the reflection preprocessor and other build time custom tools that generate code.\n\nToolchains\n\nI’m using mingw-w64 to build Windows binaries and OSX Cross to build for OSX.\n\nThis is the toolchain file I use to compile Windows 64bit binaries:\n\nset(CMAKE_SYSTEM_NAME Windows)\nset(CMAKE_SYSTEM_VERSION 1)\nset(CMAKE_SYSTEM_PROCESSOR x86_64)\nset(TOOLCHAIN_PREFIX x86_64-w64-mingw32)\n\nset(CMAKE_C_COMPILER     \"${TOOLCHAIN_PREFIX}-gcc\")\nset(CMAKE_CXX_COMPILER   \"${TOOLCHAIN_PREFIX}-g++\")\n\nset(CMAKE_FIND_ROOT_PATH_MODE_PROGRAM NEVER)\nset(CMAKE_FIND_ROOT_PATH_MODE_LIBRARY ONLY)\nset(CMAKE_FIND_ROOT_PATH_MODE_INCLUDE ONLY)\nset(CMAKE_CROSS_COMPILING TRUE)\n\nOther toolchain files are similar, the only change is x86_64 to i686 and the TOOLCHAIN_PREFIX. You can read more about cross-compiling with Cmake on the docs.\n\nThe variable CMAKE_CROSS_COMPILING is used throughout the CMakeLists.txt files to disable running of preprocessing tools I mentioned earlier.\n\nBuilding\n\nThe actual build process is rather simple: the same bash script I mentioned above serially runs Ninja on each folder like so:\n\n  ninja -C build/&lt;platform&gt;\n\nIf the build fails the stderr is redirected to a BUILD_ERRORS.txt file that I can later review.\nWhenever a build breaks for a platform I run the same toolchain on my main development workstation and fix the bugs.\n\nI’m currently building only in debug mode, but when I’ll integrate automated testing for I’ll enable Release mode to. Cross-platform automated testing will be tricky as I’ll probably have to use some form of OS virtualization.\n\nObviously a successful build doesn’t mean the actual game will run on the target platform, but that will be (hopefully) handled when I implement automated testing.\n\n","preview":"I’ve moved permanently to Linux as my development platform. I’m in love! Linux is giving me even more freedom from clutter and OS annoyances than what OSX was giving me....","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":40,"type":"post","title":"<b>#10</b>Collision Detection and More Linux Stuff","url":"/rival-fortress-update-10-collision-detection-and-more-linux-stuff/index.html","game":"rival-fortress","date":"Mar 7, 2016","gameName":"Rival Fortress","content":"This week I started working on collision detection for Rival Fortress.\n\nSince I’ll be rolling my custom collision detection/physics solution I had to do a lot of groundwork that you don’t have to do if you pick up an off-the-shelf middleware like Nvidia Physx or Havok.\n\nThe upside is that custom solution is lean and mean and fits like a glove, plus I’m learning a lot about the inner workings and trade-offs that you usually don’t have to deal with or don’t care about, but affect your game in some way or another.\n\nI’m using the excellent Real-Time Collision Detection along with Game Physics as references, as I’ve never wrote the whole stack from scratch before.\n\nMore Linux Stuff\n\nThis weekend I did a little more Linux tinkering. I dived into the fascinating world of Live CD distributions.\n\nIn particular I used Porteus, a customizable micro distribution based on Slackware, to set up a 8GB USB thumb drive everything I need to code, debug and test Rival Fortress.\n\nI can just plug in the USB drive in any x86_64 computer (PC or Mac) with at least 2GB of RAM, boot from it, and code away.\n\nThe customization process was relatively straightforward, but I had to build a lot of the tools I use from source as the versions on USM, the Slackware package manager that Porteus supports, are out of date.\n\n","preview":"This week I started working on collision detection for Rival Fortress. Since I’ll be rolling my custom collision detection/physics solution I had to do a lot of groundwork that you...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":41,"type":"post","title":"Faster Cross-Platform Game Testing with Synergy","url":"/faster-cross-platform-game-testing-with-synergy/index.html","game":"","date":"Feb 29, 2016","gameName":"","content":"\n\n\nNOTE: If you are a game developer with access to two or more monitor and an extra PC or laptop, this post may interest you.\n\nCross-platform game development is a wide topic.\n\nThis post is not about the technical aspects of it.\n\nIt is about doing your best to offer a very similar experience on all the platforms you are targeting. It is about keeping platforms in sync before it is too costly to make changes. It is about not introducing too much overhead in your already tight schedule.\n\nThree platforms, one cup keyboard\n\nEach platform has its idiosyncrasies.\n\nWhether you are using an off-the-shelf engine with a “Publish to X” button or are a proponent of the Handmade Manifesto, testing your target platforms early and often is important to ensure no crazy platform specific bugs are slipping through the cracks.\n\nNo one wants nasty surprises that force you to double back on design/architectural decisions because of platform differences late in the development cycle.\n\nIf you are lucky enough to have the resources to allocate specific team members to cross-platform duty you probably don’t need to read the rest of the post, but if, like me, have to juggle multiple roles, read on.\n\nThe magic of Synergy\n\nThe way I’m handling cross-platform testing/development on my current project is based on a software called Synergy.\n\nSynergy is a fantastic piece of software that allows seamless mouse, keyboard and clipboard sharing between multiple computers.\nIt is available as both a $10 paid version to help support development, but also as open source (GPL) from their official GitHub repo that you can compile yourself.\n\nYou can find the guide on how to compile Synergy on the project Wiki.\n\nSynergy also offers nightly builds for all supported platforms if you don’t mind using an unstable version.\n\n\n\n\nMy Synergy setup\n\nI have two PCs and a Mac (Windows 8, Ubuntu 15.10, and OSX 10.11) on the same wired network and I use Synergy to control all three with just one keyboard and mouse.\n\nI have them setup like so:\n\n\n  \n    The main terminal is in the middle: a 27” iMac to which the keyboard and mouse are connected. I spend most of my time looking at this screen, as this is where I code. I describe my workflow further down this post.\n  \n  \n    To my left is my game testing terminal: a PC running Windows 8. I use it to interact with the game proper that I launch while debugging since it has the most horsepower (a Radeon R9 290x).\nThe keyboard/mouse are replicated by Synergy and I have an Xbox 360 controller directly connected to the Windows machine, in case I need to mash some buttons.\n  \n  \n    To my right is my debugging/build terminal: an old PC running Ubuntu 15.10. I use it mostly for building and cross-compiling whenever I commit. I sometimes launch the game on this machine as well, just to test the low res path, as the graphics card on this is quite old.\n  \n\n\nSynergy settings\n\nSince I have no keyboard attached, I set Windows and Linux to auto-login and start the Synergy daemon on startup.\n\nThis are the setting I use for Synergy on the three platforms:\n\nSynergy on OSX\nSynergy on OSX requires assistive devices, so you must run it from the .app bundle on the latest versions of OSX. To start it automatically when the Mac boots, enable automatic login and add Synergy.app to your Login Items like so:\n\n\n\n\nSynergy on Windows\nSynergy on Windows is automatically configured by the installer. You only need to enable automatic login for the account you want to share in case you are using the Windows machine as a client.\n\n\n\n\nSynergy on Ubuntu\nOn Ubuntu I chose to start Synergy as a start up application, but you can add it to your lightdm configuration as a startup session as described here.\n\nThis is the command I use:\n\n/opt/synergy/synergyc --daemon --log /var/logs/synergy.log SERVER_IP\n\n\n\n\nMental context-switches\nThe minor downside of using Synergy, is that you have to learn how to deal with the mental context-switches that happen when you pass from an OS to the other.\n\nFor example, keyboard shortcuts are often different, particularly from OSX to Windows/Linux: I sometimes press Win+C when I intended to press Ctrl+C or vice-versa, especially if I’m quickly swapping between monitors.\n\nI could probably remap the modifier keys to be more uniform between platforms, but I’d rather not deal with that can of worms.\n\nUsing Synergy with an off-the-shelf engine\n\nIf you are using Unity, Unreal, Lumberyard, or any other off-the-shelf engine I think this approach can work for you.\n\nAs long as you have two or more computers (or laptops) in your network you can link them up with Synergy, install a copy of the editor on each computer and iterate faster on changes.\n\nYou could setup a shared network folder and keep all your project files on there, so all changes are reflected immediately on all the clients.\n\nUnfortunately I don’t have personal experience with the workflows used by any of these engines so your mileage may vary.\n\nUsing Synergy with a in-house engine\n\nIf, like me, you are using an in-house engine for your game I think this approach is invaluable.\n\nYou can write custom functionality that interfaces your engine with Synergy using the Plugin API.\n\nSomething I’m working on is an event system that automatically coalesces logs from all the clients in a centralized location so I can better debug from my main terminal.\n\nAnother useful plugin could allow your artist to quickly iterate on models or graphics by working on their primary workstation, and seeing updates reflected on all clients simultaneously.\n\nA concrete exemple: My coding workflow\nFor Rival Fortress, the game I’m developing, I’m using a workflow that is very terminal centric.\n\n\n  I start on my iMac by opening three iTerm windows.\n\n\n\n\n  In one of the terminal windows launch my main Tmux session.\nThis it what it looks like:\n\n\n\n\n\n  I ssh into both Windows and Linux, from the two remaining iTerm windows using the following command:\nssh HOSTNAME_OR_IP -t \"tmux new-session -t gamedev || tmux new-session -s gamedev\"\nThis command connects to the host and attaches to the gamedev Tmux session if present, otherwise it creates a new one.\nYou can add the -Y if you want to forward your X11 (This only applies to OSX/Linux).\n\n\n\n\nI have Cygwin installed on Windows. This allows me to run Tmux, terminal VIM, and all the other *nix tools I use on a daily basis.\n\n  Once I’m in, I restore my Tmux layout using Tmux Resurrect (a fantastic plugin by the way). The Tmux layout I use on the client machines is almost identical to the one I use on my main machine.\n  Whenever I want to debug the game on any of the platforms I launch it from lldb or gdb.\n\n\nOther ways to do cross-platform development\n\nSynergy is not the only way to do cross-platform game dev.\nWhat follows is not meant as a comprehensive list, just a general summary.\n\nThe needs of each team (or solo developer) are different and often the “best” solutions are ad-hoc hybrids of the ones I’m about to outline.\n\nEnd-of-cycle porting\nThe simplest approach is to develop on the main platform (usually Windows) and wait until the end of the development cycle before porting to other platforms.\n\nContinuous Integration\nA more sophisticated approach is to use Continuous Integration, and automatically run builds on all of target platforms when code is committed to source control.\nThis strategy is essential for mid-to-large teams, but I think that for most micro teams or solo Indie developers the overhead of setting up and maintaining a CI toolchain is too high.\n\nVMs and Containers\nAnother common approach is to use Virtualization or Software Containers with target platform images that you can spin-up when you want to test a build. Unfortunately graphics support on most VMs is minimal, and to my knowledge the best you can get while running inside a VM is OpenGL 3.2.\nThis may be enough if you are developing a game with modest graphical requirements, but if you are squeezing every pixel from the graphics card this approach won’t cut it.\n\nPlatform farms\nFinally, there is what I call “the platform farm” approach, where you either have several desktop PC/Macs or multi-boot many installs on the same machine. This works well, as it allows you to periodically swap between platforms to test the game, but I personally don’t like the mental context-switch required when you bounce from a PC to the next or when you dual boot.\n\nOutsourcing\nSome AAA studios outsource platform porting to other studios that are specialized in doing this kind of thing (common practice in console development), but that is outside the scope of this post.\n\nWrapping it up\n\nIn conclusion I think Synergy is a very useful tool for game development, especially Indies. No matter what tools you are using, having quick access to another platform can really improve the long term polish of your game.\n\n\n\nImage credits:\n\n\n  https://www.iconfinder.com/Blagochevsky\n  http://www.webalys.com/\n  http://www.proglyphs.com/\n\n","preview":"NOTE: If you are a game developer with access to two or more monitor and an extra PC or laptop, this post may interest you. Cross-platform game development is a...","categories":"[&quot;technical&quot;, &quot;game&quot;, &quot;development&quot;, &quot;cross-platform&quot;, &quot;other&quot;]"},{"id":42,"type":"post","title":"<b>#9</b>It's Vulkan Week","url":"/rival-fortress-update-9-its-vulkan-week/index.html","game":"rival-fortress","date":"Feb 22, 2016","gameName":"Rival Fortress","content":"Vulkan was announced this week. It’s looks promising and I can’t wait to start hacking on it to see what’s under the hood.\nUnfortunately Apple has no intention of supporting Vulkan on OSX, as Metal is the API they are pushing, so I’ll have to choose either Windows or Linux.\n\nI talked about why I chose OSX  as my main development platform in a previous post: I spend much of my development time in the terminal, in both VIM, lldb/gdb and the command line. I tried using Cygwin on Windows in the past, but I just couldn’t get into it.\n\nSo this past week I downloaded the latest Ubuntu iso and dual booted it on Windows 8.1 machine.\nI went with Ubuntu as it seems like the most popular consumer Linux distribution, as well as the only distribution with official Vulkan SDK support from LunarG.\n\nModern Linux is pretty nice\n\nIt’s been a long time, probably more than 15 years, since I used a desktop Linux distribution. I’m only used to ssh-ing into the occasional server, but that’s essentially the same as OSX’s BSD layer.\n\nWhen I booted up from the USB stick I had flashbacks of when back in the day installing Linux was a nightmare of missing drivers and iterative attempts, but Canonical did an excellent job with the installer: in less than 10 minutes I was clicking away on the Ubuntu desktop.\n\nFor OSX I have quite a few .dotfiles for my development setup, that I was able to use on Linux with almost zero changes.\nThe only gotcha I came across was having to disable tmux-MacOSX-pasteboard like so:\n\nif-shell 'test \"$(uname -s)\" = Darwin' 'set-option -g default-command \"exec reattach-to-user-namespace -l zsh\"'\n\nMy current workflow is:\n\n\n  SSH into Linux from my iMac (until I upgrade the monitor of my Windows/Linux box, I can’t give up the 27” real-estate)\n  Connect to the tmux server running on Linux\n  Connect via VNC to the Linux box and keep the remote desktop window open on the second monitor connected to the iMac\n  Write code/debug from lldb/gdb normally\n  Run the game and test from the remote desktop\n\n\nDeveloping on OpenGL 4.x with Ubuntu\n\nI don’t know about other distributions, but the default drivers provided by Canonical only support OpenGL 3.x and no development headers are installed. \nTo fix this I downloaded the latest Linux drivers from AMD (I have a Radeon R290X) as well as the mesa-common-dev and xorg-dev packages to have access to all the OpenGL headers.\n\nOther than that I’m currently working porting platform specific code for Rival Fortress, and maybe next I’ll take a look at how to shovel some Vulkan goodness in the engine renderer :).\n","preview":"Vulkan was announced this week. It’s looks promising and I can’t wait to start hacking on it to see what’s under the hood. Unfortunately Apple has no intention of supporting...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":43,"type":"post","title":"<b>#8</b>Embedding Lua for Modding","url":"/rival-fortress-update-8-embedding-lua-for-modding/index.html","game":"rival-fortress","date":"Feb 15, 2016","gameName":"Rival Fortress","content":"The engine for Rival Fortress is coming along nicely, and in a few weeks I’ll probably start working on game code.\n\nThis past week I integrated LuaJIT in the engine. LuaJIT is a just in time interpreter for the Lua language that is lightweight and very fast.\n\nIntegrating LuaJIT\n\nI’m statically linking the LuaJIT runtime as I intend to make some modifications to the implementation, especially to the memory allocation routines.\n\nOther than that integration was quick an painless. The only tedious part was converting the Makefile based build system that LuaJIT uses into my CMake toolchain.\nIf you are looking to do something similar I suggest starting from the CMakeLists.txt in the luajit-rocks repo.\n\nExposing an API to Lua\n\nIn the engine I’m using Lua to expose an API that can be consumed by scripts and used in modding.\n\nThe API consists of a global Lua table that contains various functions that the modder can use to initialize the mod and register callbacks to specific events in the game lifetime.\nThe API is still quite bare bones, as I intend to expose functionality as I need it while working on the actual game code. The idea is that most of the game specific logic will be implemented in Lua within the constraints of the engine.\n\nUsing reflection to expose functionality\n\nI’m using the reflection system I talked about the previous week to expose functionality to Lua. I do so by annotating structs and functions and the reflection system generates the boilerplate code needed to glue C and Lua together.\n\nThis is particularly useful for handling Lua-to-C type conversion and Lua Stack management.\n","preview":"The engine for Rival Fortress is coming along nicely, and in a few weeks I’ll probably start working on game code. This past week I integrated LuaJIT in the engine....","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":44,"type":"post","title":"<b>#7</b>Reflection Preprocessor in C/C++","url":"/rival-fortress-update-7-reflection-preprocessor-in-c-cpp/index.html","game":"rival-fortress","date":"Feb 8, 2016","gameName":"Rival Fortress","content":"This past week I’ve been working on a useful engine feature for Rival Fortress: the Reflection Preprocessor.\n\nReflection is usually defined as the ability of a program to examine itself at runtime. Many programming languages, such as C# and Java, offer built in semantics that make reflection easy.\nC++ offers a few tools, in the form of RTTI and templates, but while working on previous projects I found them to come at a performance cost (in case of RTTI) or a compile time cost (in the case of templates.)\n\nFor Rival Fortress I decided to build on the asset preprocessor and opengl generator by creating a preprocessor that parses source files looking for annotated sections and generate relevant code.\n\nThe Reflection Preprocessor\nThe preprocessor is a program written in C++ that tokenizes source files looking for code annotated with MREFLECT(...). Between the parenthesis are directives that tell the preprocessor what to do with the code that follows.\n\nThe preprocessor runs as part of the build, before anything else, and generates a Reflection.generated.h that is included by the main headers of each translation unit (I currently only use 2 translation units, one for the game+engine and one for the editor+engine).\n\nIt only runs on files that have been changed since the timestamp of the last generated file, to keep things super fast. On a cold build it can parse roughly 120 files in less than 0.1 seconds, so it adds very little overhead to the build process.\n\nReflection for configuration\n\nAn example of how I use the preprocessor is to generate configuration reader and writer automatically. \nThe following is an excerpt of the annotated Config struct that holds configuration settings that the user can edit:\n\nMREFLECT(Struct)\nstruct MPEConfig\n{\n  char* ReadPath;\n  char* WritePath;\n\n  MREFLECT(Config:\"Engine\", Default: DEFAULT_MAX_MEMORY,\n           Min: MIN_MAX_MEMORY, Max: MAX_MAX_MEMORY,\n           Comment: LOC(\"Max memory that the engine will use\")\n  u64 MaxMemory;\n\n  MREFLECT(Config:\"Engine\", Default: DEFAULT_FULLSCREEN_MODE)\n  MPEFullscreenMode FullscreenMode;\n\n  MREFLECT(Config:\"Engine\", Default: DEFAULT_WINDOW_WIDTH,\n           Min: MIN_WINDOW_WIDTH)\n  i16 WindowWidth;\n  MREFLECT(Config:\"Engine\", Default: DEFAULT_WINDOW_HEIGHT,\n           Min: MIN_WINDOW_HEIGHT)\n  i16 WindowHeight;\n\n  // Other members below\n}\n\nWhen the reflection preprocessor parses this struct it will automatically generate functions to read/write the config file (in .INI format) with the appropriate parser functions for the types specified and validation for eventual min/max values, as well as default values.\n\nThe relevant tokens are:\n\n  Config: the member should be exposed in the config file under the specified section (in the previous example the section is [Engine])\n  Default: the member has a default value\n  Min/Max: the member has a min/max value\n  Comment: a localized comment that is placed before the member in the config value\n\n\nMember values that are not annotated with MREFLECT are not written to the configuration file.\nThe preprocessor also keeps track of the struct from witch each member came from and when generating the reader/writer functions adds the appropriate parameters of those types.\n\nThis makes it very easy to quickly expose configuration settings from anywhere in the project.\n\nThis is the output .ini that gets generated:\n\n[Engine]\n; Max memory that the engine will use\nMaxMemory=1073741824\n; Allowed values:\n; - BorderlessFullscreen\n; - Fullscreen\n; - Windowed\nFullscreenMode=Windowed\nWindowWidth=960\nWindowHeight=600\n\nAs you can see the enum MPEFullscreenMode is treated as a string by stripping redundant prefixes and all possible enum values are prepended to the configuration setting as comments, so the user can easy make changes.\n\nReflection for much more\n\nI’m currently adding features to the reflection preprocessor as need arises, and I expect it will become more and more useful as time goes on.\nFor example generating data structures automatically (i.e. Hash tables, resizable arrays) based on types, without having to resort to C++ templates is a plus for me. It keeps compile times super fast, and that’s the way I like it.\n","preview":"This past week I’ve been working on a useful engine feature for Rival Fortress: the Reflection Preprocessor. Reflection is usually defined as the ability of a program to examine itself...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;rival-fortress&quot;]"},{"id":45,"type":"post","title":"<b>#6</b>OpenGL Minimal Loader","url":"/rival-fortress-update-6-opengl-loader/index.html","game":"rival-fortress","date":"Feb 1, 2016","gameName":"Rival Fortress","content":"If you’ve ever worked with OpenGL you know that extension loading is always a bit of a pain.\n\nYou can either do it manually, by loading the correct library for your platform and getting function pointers for the OpenGL functions you need, or you can use one of the many extension loaders, like GLEW, GL3W.\n\nSince with Rival Fortress I’m trying to minimize dependencies for a number of reasons, I decided to roll my own extension loader.\n\nglgen\nglgen is a command line tool that generates an header file with a minimal extension loader. The loader only loads OpenGL functions that are actually made in the project.\n\nThe generator works by parsing project files and generating typedefs, #defines and function pointers using definitions that are extracted from header files provided by the Khronos OpenGL API registry.\n\nThe biggest advantage over traditional OpenGL extension loaders is a faster startup time for your application, as well as a better view on what OpenGL functions you are actually using.\n\nThe tool is currently very simple and naive, as it only looks for tokens that start with gl or GL_ but I’ll probably add better token parsing as the need arises.\nIn its current form it is perfect for rapid development.\n\nglgen with CMake\n\nThe tool is part of my CMakeLists.txt and it is run on every build since all my OpenGL calls are made from a couple of files, so builds are still blazing fast.\n\nTake a look at the Readme on the project file for more information about glgen.\n","preview":"If you’ve ever worked with OpenGL you know that extension loading is always a bit of a pain. You can either do it manually, by loading the correct library for...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":46,"type":"post","title":"<b>#5</b>Cross Platform Development","url":"/rival-fortress-update-5-cross-platform-development/index.html","game":"rival-fortress","date":"Jan 25, 2016","gameName":"Rival Fortress","content":"This week has been cross platform week for Rival Fortress.\n\nI’ve been trying to set up a toolchain that can allow me to easily compile the game on Windows, Linux and Mac, from a single build machine.\nSince my main development platform is OSX, the first thing I tried was using Mingw-w64 alongside GCC to build for both Windows and Linux.\nAfter a lot of fussing around I was able to get the game to build for both Win32/64 and Linux 32/64, but unfortunately GCC is not able to output PDB debug symbols, so while in development, I will still have to compile with Visual Studio to be able to debug on Windows.\n\nBut the big question is:\n\nWhy game development on a Mac?\n\nMac OSX is not a common platform for game developers that aren’t targeting primarily Apple’s mobile products.\nVisual Studio is an excellent IDE with a fantastic (probably the best) graphical debugger, so it seems like a no-brainer for an Indie game dev to choose Windows.\n\nI was a Windows developer for 12 years, before and after .NET was a thing.\nAbout 8 years ago I bought a Mac out of curiosity, and that’s when I discovered that “living in the shell” could give me a new level of productivity and freedom that Visual Studio or any other IDE just couldn’t give me.\nI still have a Windows machine that I mostly use for gaming, and a little debuggin when I have to make sure my code runs on Windows, but all of my development is done on a Mac.\n\nWriting game code on OSX\n\nMy terminal is iTerm2 that I always keep fullscreen while I’m developing.\n\nI write code in Neovim that, combined with Tmux, allows me to fly through code at a much faster pace than when working with any other IDE.\nOSX comes with Xcode but, unless you are doing iOS development, I find it to be a mediocre IDE with sub-par debugging tools.\n\nThis is how my setup looks like (the screenshot is 2560x1440):\n\n\nThe top two panes are Neovim, where I keep two files open most of the time. At the bottom I have a Zsh shell for when I need to do some Hub operations, and on the right is a tail -f of the game log. I usually zoom the Neovim pane using Tmux’s &lt;prefix&gt;z when I’m in “Flow”.\n\nDebugging game code on OSX\n\nMy debugger of choice is LLDB. It’s a fantastic debugger once you customize it to fit your needs. It takes some time to get used to, especially if you are used to GUI debugging, but I find it almost rivals Visual Studio when it comes to giving you the information you need to quickly locate those pesky bugs.\n\nThis is what a typical debugging session looks like:(the screenshot is 2560x1440)\n\n\nThe left pane is LLDB customized with a .lldbinit to show me the information I usually need based on the type of debugging I’m doing. I also have another .lldbinit in the project directory that I use to format custom data types.\nOn the right pane at the top is a Neovim session that I use to take notes or open miscellaneous files. \nAt the bottom right is another tail -f of the game log colorized based on the serverity of the log.\n\nWhile I’m developing I never need to touch the mouse.\n","preview":"This week has been cross platform week for Rival Fortress. I’ve been trying to set up a toolchain that can allow me to easily compile the game on Windows, Linux...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;assets&quot;, &quot;rival-fortress&quot;]"},{"id":47,"type":"post","title":"<b>#4</b>Offline and Runtime Bitmap Fonts","url":"/rival-fortress-update-4-offline-and-runtime-bitmap-fonts/index.html","game":"rival-fortress","date":"Jan 18, 2016","gameName":"Rival Fortress","content":"This week I finally tackled font rendering for Rival Fortress’s game engine.\n\nAfter a few iterations I decided to use pre-cooked bitmap fonts for the debug overlays and True-Type runtime rasterization for the game proper. For both paths I’m using Sean Barret’s excellent stb_truetype library, along with stb_rect_pack to pack multiple font sizes into a texture atlas.\nI also did some testing using distance field fonts[PDF] but I couldn’t find a way to render them with reasonable performance without sacrificing too much detail. For now I’ll just stick with bitmap fonts.\n\nOffline Pre-cooked Bitmap Fonts\n\nThe font used for debug overlays is Roboto Mono. To reduce the size of the font I extracted just glyphs ranging from ASCII 0x20 to 0x98, which is essentially all alpha-numeric characters and the most common punctuation marks. I used FontForge for glyph extraction.\n\nThe preprocessing is done offline, by a tool that is run as part of the build pipeline when the font changes.\nThe tool rasterizes the glyphs and packs them into a texture atlas. The texture atlas is then compressed using a simple compression algorithm and encoded using Base85. \nThe Base85 encoded string is embedded in a generated C++ header file as a char* and included by the game engine. This meas that in case something goes wrong during asset initialization and I want to gracefully warn the user.\n\nThe reason I decided to pre-cook the debug font is that since I will only ever use a very small glyph range and the font size will never change, there is no need to pay the rasterization cost at runtime (albeit minimal).\n\nI was inspired by Orcut’s great Imgui library uses that uses a similar approach, but instead of rasterizing, the True-Type font is embedded directly.\n\nOn an optimization note: Roboto Mono is certainly overkill for just the debugging overlay, as the glyphs contain quite a bit of detail that increases the compressed font size (the compressed and Base85 encoded string is a little over 10k bytes). In a future iteration I will most likely switch to a simpler font.\n\nRuntime Rasterized Bitmap Fonts\n\nThe main game will use True-Type fonts that are rasterized at runtime. This allows greater flexibility as you can render the correct size fonts based on the user’s resolution as well as only rasterize the glyphs needed by the user’s locale, thus reducing the texture atlas size.\n\nI’m using two fonts currently, that are both packed as byte arrays, along with a bit of metadata, into the PAK file. I talked about the engine’s asset pipeline in previous posts.\n\nThe metadata stored in the PAK is minimal (max glyph size, glyph count, unicode codepoint ranges). Kerning tables are calculated at runtime based on the glyph ranges needs, but I’ll have to test if pre-calculating them and storing them in the PAK is better.\n\nAt runtime the fonts are lazily loaded when any one of the game modules needs to render text. \nCurrently I’m allocating a fixed size texture atlas that I progressively fill with rasterized glyphs and upload to the graphics card whenever it is updated. Only the subset of the texture atlas that contains bitmap information is sent to the card.\n\n","preview":"This week I finally tackled font rendering for Rival Fortress’s game engine. After a few iterations I decided to use pre-cooked bitmap fonts for the debug overlays and True-Type runtime...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;assets&quot;, &quot;rival-fortress&quot;]"},{"id":48,"type":"post","title":"<b>#3</b>More Game Asset Preprocessing","url":"/rival-fortress-update-3-more-game-asset-preprocessing/index.html","game":"rival-fortress","date":"Jan 11, 2016","gameName":"Rival Fortress","content":"Last week I talked about the asset preprocessing pipeline that I’m working on for Rival Fortress: essentially all game and engine assets are preprocessed and packed into a single giant file that is optimized for faster loading during runtime.\n\nThis week, while tackling font rendering, I’ve refined the asset packer and added a few more features.\n\nHot reloading assets\n\nThe most useful feature is the ability to re-pack and reload assets while the game is running. The code responsible for this is the same that I talked about in the post about hot-swappable modules. This makes for faster iteration times, especially when working on shaders.\n\nThe engine can also detect new asset .PAK files while running and pull them in automatically. I intend to leverage this functionality in the future when I start working on the modding API.\n\nStreamlined asset manifest\n\nI also streamlined the JSON manifest that specifies how game assets should be pre-processed, and it now looks like so:\n\n{\n  \"fonts\":\n  [\n    {\n      \"name\": \"Large\",\n      \"filename\": \"fonts/test.ttf\",\n      \"size\": 32,\n      \"range_start\": 32,\n      \"range_end\": 126\n    }\n  ],\n  \"materials\":\n  [\n    {\n      \"name\": \"Stone\",\n      \"shaders\":\n      [\n        \"shaders/stone.frag\",\n        \"shaders/stone.vert\"\n      ]\n    },\n    {\n      \"name\": \"HUD\",\n      \"shaders\":\n      [\n        \"shaders/hud.frag\",\n        \"shaders/hud.vert\"\n      ]\n    }\n  ],\n  \"meshes\":\n  [\n    \"meshes/plane.obj\",\n    \"meshes/cube.obj\",\n  ],\n  \"images\":\n  [\n    \"images/test.jpg\",\n    \"images/test2.jpg\",\n  ]\n}\n\nI’ve also added Materials and Fonts as asset types, but I’m still weighing pro and cons of different font rendering approaches.\n\nCommand line interface\n\nWhile merging the asset packer (that was previously a separate tool) with the main executable I also added command line argument parsing. \nNow the game executable can start in different modes depending on the command line arguments. For example if I want to run the asset packer as part of the build chain, I can pass the -t packer argument and the game will behave like a command line tool and won’t initialize all game related sub-systems.\n\n","preview":"Last week I talked about the asset preprocessing pipeline that I’m working on for Rival Fortress: essentially all game and engine assets are preprocessed and packed into a single giant...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;assets&quot;, &quot;engine-tech&quot;, &quot;rival-fortress&quot;]"},{"id":49,"type":"post","title":"<b>#2</b>Preprocessing and Bundling Game Assets","url":"/rival-fortress-update-2-preprocessing-and-bundling-game-assets/index.html","game":"rival-fortress","date":"Jan 4, 2016","gameName":"Rival Fortress","content":"Taking a page from the awesome Handmade Hero I decided to pre-process game assets in a format more suitable for game consumption. You can take a look at how Casey approaches it starting from Day 150 of his series.\n\nRival Fortress is a 3D game, so it uses a variety of assets type: textures, normal maps, fonts, meshes, shaders, etc., and each type benefits from a little preprocessing before being used by the actual game engine.\n\nFor this reason I wrote a simple command line tool that reads a JSON manifest that contains a list of the assets needed by the game, along with some metadata needed by the preprocessor, and spits out a PAK file that the game engine consumes.\n\nThe manifest looks like this:\n\n[\n  {\n    \"type\": \"vertexshader\",\n    \"filename\": \"shaders/example.vert\",\n  },\n  {\n    \"type\": \"fragmentshader\",\n    \"filename\": \"shaders/example.frag\"\n  },\n  {\n    \"type\": \"geometryshader\",\n    \"filename\": \"shaders/example.geom\"\n  },\n  {\n    \"type\": \"mesh\",\n    \"filename\": \"meshes/cube.obj\"\n  },\n  {\n    \"type\": \"mesh\",\n    \"filename\": \"meshes/sphere.obj\"\n  },\n  {\n    \"filename\": \"images/test.jpg\",\n    \"type\": \"texture\"\n  },\n  {\n    \"filename\": \"images/test2.tga\",\n    \"type\": \"normalmap\"\n  },\n]\n\nThe PAK file format\n\nThe file format I chose is similar to the old Quake PAK: a header, a directory, followed by the asset data.\n\nThe file begins with a header that is laid out like so:\n\n\n  Header\n  (4 bytes) signature = 'MPAK'\n  (4 bytes, uint) version number\n  (4 bytes, uint) asset count\n\n\nAfter that is the directory of assets, that is an array of the following elements:\n\n\n  Directory entry\n  (4 bytes, uint) numerical ID\n  (4 bytes, enum) asset type\n  (8 bytes, uint64) size in bytes\n  (8 bytes, uint64) byte offset within file\n\n\nThe numerical ID of the asset is a 32-bit FNV-1 hash of the filename of the asset as specified in the Manifest.json  file.\nThe preprocessor also spits out a .generated.h file, that is included in the build and contains an enum with all the assets and their ID.\nWith this approach the string hash is computed offline and in no place in the actual game code are assets referred to by their filename, faster lookups by cutting out string comparisons.\n\nFinally the actual asset data is dependent of the asset type, and contains any metadata related to the asset itself. For example, meshes include the vertex array data as well as uints for the number of verts, normals, texcoords and indices.\n\nPreprocessing shaders\n\nUnfortunately, unlike their DirectX counterparts, OpenGL shaders cannot be precompiled, so all we can do is some basic text manipulation and validation.\nTo do so, the files are squished by removing excess whitespace and comments and compiled with OpenGL to check for syntax errors. The source code is then written into the PAK file.\n\nPreprocessing images\n\nImages are loaded into memory as a raw RGB or RGBA byte stream, flipped on the Y axis and written to the PAK file. In a future iteration of the asset preprocessor I’ll likely compress the images with DXTn as the PAK file is getting kinda bloated with uncompressed images.\n\nPreprocessing meshes\n\nI chose the Wavefront .obj file format for meshes because it is a very simple format. I wrote a simplified parser that can digest only triangulated meshes and has very simple material loading capabilities. I’ll revise it when I’ll get a firmer grip on the rendering requirements for Rival Fortress.\nMesh vertex, normal and texture coordinate data is interleaved into a large float array for better cache locality. This will be used as a single Vertex Buffer Object (VBO) by OpenGL.\n\nPreprocessing fonts\n\nI still haven’t tackled font preprocessing, because I’m still unsure as to how I will handle text rendering in the game.\n\n","preview":"Taking a page from the awesome Handmade Hero I decided to pre-process game assets in a format more suitable for game consumption. You can take a look at how Casey...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;assets&quot;, &quot;rival-fortress&quot;]"},{"id":50,"type":"post","title":"<b>#1</b>Hot Swappable Game Modules","url":"/rival-fortress-update-1-hot-swappable-game-modules/index.html","game":"rival-fortress","date":"Dec 28, 2015","gameName":"Rival Fortress","content":"Rival Fortress will use a custom 3D game engine that I’m building from scratch in C++ and a bit of Assembly.\nCurrently the only dependencies for the game are SDL, and the truetype library from Sean Berret.\n\nThe engine is still in active development, but so far the most fun and interesting feature has been the Hot Swappable Game Modules.\n\nFast iteration\nZippy iteration times are very important to  me. I hate having to wait around for compile times and having to close and re-open the game just to see some small changes in action, especially when I’m tweaking some game mechanic.\n\nData oriented/driven\nA commonly used approach is data-oriented game engine design, or as Unreal Engine calls it data driven gameplay, where the engine supports loading gameplay variables from external files that are usually human editable, like CSV tables or Excel spreadsheets.\n\nThis works well for tweaking existing variables, but doesn’t allow you to add or remove variables, or even functions.\n\nScripting\nAnother approach often used is integrating a scripting using languages like Lua, Python or JavaScript in the game engine. This is dobe by exposing bindings to the scripting language and a callable API that can be used to modify in real time game behavior.\n\nThis can be very useful, especially when thinking about game moddability, but the cost is in performance: A scripting language will never be as fast as native well optimized C/C++.\n\nModularity\n\nThe route I chose to take for Rival Fortress is to split the engine and game into shared libraries (DLLs for Windows, dylibs for OSX and libs on Linux).\nThe game itself is launched through a thin shell executable that takes care of the initial bootstrapping and in turn loads all compatible libraries found in the game directory.\n\nThis is the stripped down part that makes it happen:\n\nfor(u32 LibIdx = 0; LibIdx &lt; LibCount; ++LibIdx)\n{\n  MPEGameLib* GameLib = MPE_LoadGameLib(Engine, GameLibs[LibIdx]);\n  if (GameLib)\n  {\n    // Lib initialization\n  }\n  else\n  {\n    MPE_LogWarn(\"Couldn't load: %s\", GameLibs[LibIdx]);\n  }\n}\n\nGameLibs is an array of char* (wchar_t on Windows) filenames populated by crawling the game directory and looking for libraries supported by the host operative system.\nMPE_LoadGameLib tries to load the shared library in memory and checks if it provides a valid entry point like so:\n\nGameLib-&gt;Handle = dlopen(GameLib-&gt;Path, RTLD_LAZY | RTLD_GLOBAL);\nif (GameLib-&gt;Handle)\n{\n  auto EntryPoint = (MPEGameLibMetadata(*)())dlsym(GameLib-&gt;Handle, MPE_GAME_LIB_METADATA);\n  if (EntryPoint)\n  {\n    // Populate GameLib metadata\n  }\n}\n\nEntryPoint is a function pointer that returns metadata information of the library, like version, dependencies, run priority, etc. It also contains the API with function pointers that will be called by the shell during execution, like so:\n\nstruct MPEGameLibAPI\n{\n  MPELibState* (*Initialize)(MPEEngine* Engine, MPEGameState* GameState);\n  void (*Shutdown)(MPEEngine* Engine, MPEGameState* GameState, MPELibState* State);\n  void (*Reload)(MPEEngine* Engine, MPEGameState* GameState, MPELibState* State);\n  void (*Unload)(MPEEngine* Engine, MPEGameState* GameState, MPELibState* State);\n  void (*Step)(MPEEngine* Engine, MPEGameState* GameState, MPELibState* State);\n};\n\nAs you can see, each library has its own state that is allocated from the main game allocator, as well as access to the engine and the global GameState.\n\nThe Game Loop\n\nEverything comes together in the main game loop as you can see in the following excerpt:\n\nwhile(Engine-&gt;GameRunning)\n{\n  // Some stuff before\n  for (MPEGameLib* GameLib = Engine-&gt;FirstGameLib;\n        GameLib;\n        GameLib = GameLib-&gt;Next)\n  {\n    if (GameLib-&gt;IsStale)\n    {\n      MPE_Reload(GameLib);\n    }\n    GameLib-&gt;API.Step(Engine, GameState, GameLib-&gt;State);\n  }\n  // Some stuff after\n}\n\nEach time through the main loop a link list sorted by priority is walked. Each module is reloaded if stale and the Step function pointer is called.\n\nThe Janitor does all the work\n\nTo ensure game modules are always up to date, the engine keeps a Janitor worker in a low priority thread that keeps checking the last write timestamp of the loaded modules, as well as looking for new modules in the game directory, and keeping the linked list sorted.\n\nHot swappability\n\nThis allows the game to be edited and tweaked in real-time, as each recompile is picked up immediately.\n\nThe game state of each module is also preserved, since the main shell owns the memory from which it is allocated (I’ll talk more about the memory model used in Rival Fortress in a future update.)\n\nAll in all this has been a very fun feature to implement, and while is not really essential, it has been saving me a lot of “dead time” while rapidly iterating on ideas/implementations.\n","preview":"Rival Fortress will use a custom 3D game engine that I’m building from scratch in C++ and a bit of Assembly. Currently the only dependencies for the game are SDL,...","categories":"[&quot;rival-fortress&quot;, &quot;gamedev&quot;, &quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;engine-tech&quot;]"},{"id":51,"type":"post","title":"Compiling NASM Assembly with Xcode in a C/C++ Project","url":"/compiling-nasm-with-xcode-in-a-cpp-project/index.html","game":"","date":"Dec 21, 2015","gameName":"","content":"Last time I talked about how to integrate NASM in a CMake/Clang build, but if you are developing on a Mac you may want to use Xcode to debug your assembly code.\n\nXcode needs a bit of massaging in order to support NASM within a C/C++ project.\n\nGetting the latest NASM\n\nFirst I suggest you install the latest version of NASM using Homebrew like so:\n\nbrew install nasm\n\nThis will probably install nasm to /usr/local/bin, unless you changed your Homebrew config. Double-check the location of your nasm executable and open Xcode.\n\nSample C++ Project\n\nI suggest you create a blank “Command Line Tool” project in order to test the integration.\nYou can use this as an test main.cpp:\n\n#include &lt;stdio.h&gt;\n\nextern \"C\" long long GetRDTSC();\n\nint main(int, const char**)\n{\n  long long RDTSC1 = GetRDTSC();\n  long long RDTSC2 = GetRDTSC();\n  printf(\"Time-Stamp Counters: %lld - %lld\\n\", RDTSC1, RDTSC2);\n  return 0;\n}\n\nThe GetRDTSC() function returns the Time-Stamp Counter and is implemented in Assembly. In Rival Fortress rdtsc is used for timing execution of performance critical code.\n\nNow create a new assembly file. By default Xcode uses the .s extension for assembly, but I prefer .asm so I’ll use that in this example.\nThis is the code for the x86-64 assembly file using NASM syntax. The call to cpuid is required in order to avoid incorrect mesurements coused by Out of Order Execution, as detailed in the Benchmark Code Execution Paper by Intel.\n\nglobal _GetRDTSC\n\nsection .text\n\n_GetRDTSC:\n  cpuid\n  rdtsc\n  shl   rdx, 32\n  or    rax, rdx\n  ret\n\nBuilding NASM with Xcode\n\nIf you try to build the project you will receive syntax errors from Clang complaining about the invalid tokens from your .asm file.\n\nTo fix this open the Build Rules for your target and create a new rule like so:\n\n\n\n\nHere is the build script for easier copying:\n\n/usr/local/bin/nasm -f macho64 ${INPUT_FILE_PATH} -o ${SCRIPT_OUTPUT_FILE_0}\n\nAnd don’t forget to add a new Output File with the following path $(DERIVED_FILE_DIR)/${INPUT_FILE_BASE}.o.\n\nNow you should be able to build and debug your project.\n\nDebugging and Stepping through ASM code\n\nYou can step into your assembly function with Xcode by using CTRL-F7 or CTRL+click-ing the Step in button in the Xcode GUI.\n\nThe LLDB command line is also very useful in order to inspect registers since, unlike Visual Studio, Xcode lacks a Registers window.\n\nMake sure you have it open by going to View-&gt;Debug Area-&gt;Activate Console, then type LLDB commands in the (lldb) prompt.\nUse the register read command to print out the contents of the general purpose registers in hex, or print $rax to view the decimal value of a particular register.\nYou can find the LLDB Command Map on the official website.\n\n","preview":"Last time I talked about how to integrate NASM in a CMake/Clang build, but if you are developing on a Mac you may want to use Xcode to debug your...","categories":"[&quot;nasm&quot;, &quot;assembly&quot;, &quot;xcode&quot;, &quot;other&quot;]"},{"id":52,"type":"post","title":"Using NASM with CMake and Clang","url":"/using-nasm-with-cmake-and-clang/index.html","game":"","date":"Dec 18, 2015","gameName":"","content":"Trying to integrate NASM with CMake for the build system of Rival Fortress has been tricky.\nThe documentation on the official wiki is not up to date, and in fact, states that NASM is not supported by CMake 2.6 and below, but fortunately after a little bit of digging through CMake’s source I found that NASM is indeed supported since CMake version 2.8.\n\nUsing NASM with CMake\n\nTo enable support for .asm source files in your project you have to make sure you add the C language flag to your project declaration in your CMakeLists.txt file like so:\n\nproject(RivalFortress C CXX)\n\nRival Fortress is in C++, but the C specification is required otherwise the CMake variable CMAKE_C_SIZEOF_DATA_PTR will not be set. This variable is read by the NASM CMake module during initialization and used by CMake to detect processor architecture (32/64bit) and determines the -f flag that will be passed to NASM during compilation.\n\nNext, in order to enable *.asm compilation, you must enable the ASM_NASM language like so:\n\nenable_language(ASM_NASM)\nif(CMAKE_ASM_NASM_COMPILER_LOADED)\n  set(CAN_USE_ASSEMBLER TRUE)\n  file(GLOB_RECURSE ENGINE_ASM_FILES \"src/engine/*.asm\")\n  set(ENGINE_SOURCES ${ENGINE_SOURCES} ${ENGINE_ASM_FILES})\nendif(CMAKE_ASM_NASM_COMPILER_LOADED)\n\nThis snippet of code attempts to load the ASM_NASM language compiler and checks if it has been loaded correctly. If load was successful, the CAN_USE_ASSEMBLER variable is set to TRUE and all *.asm files are globbed and added to the source files to be compiles.\n\nLater in the CMakeLists.txt you can check if assembly is supported for the current build using the CAN_USE_ASSEMBLER variable and branch like so:\n\nif(NOT CAN_USE_ASSEMBLER)\n   set(ENGINE_SOURCES ${ENGINE_SOURCES} codec_generic.cpp)\nendif(NOT CAN_USE_ASSEMBLER)\n\nNow CMake will automatically call NASM during compilation to generate object files that will be linked with other object files generated by clang.\n","preview":"Trying to integrate NASM with CMake for the build system of Rival Fortress has been tricky. The documentation on the official wiki is not up to date, and in fact,...","categories":"[&quot;technical&quot;, &quot;development&quot;, &quot;engine&quot;, &quot;assembly&quot;, &quot;osx&quot;, &quot;cross-platform&quot;, &quot;other&quot;]"},{"id":53,"type":"page","title":"Press","url":"/press","game":"","gameName":"","content":"\n  \n    \n      Hi there! The press page is coming soon.\n\n      In the mean time drop us a line and we'll get back to you.\n\n\n      \n        Press Kit\n      \n      Coming soon!\n\n      \n        Contact Details\n      \n      \n        \n          Email: contact@metricpanda.com\n        \n        \n      \n    \n  \n\n\n\n  \n    \n      Metric Panda Digest (sent monthly and \n          looks like this)\n      \n        \n        \n        \n          \n            Submit\n          \n        \n      \n      We hate spam as much as you do!\n    \n  \n\n\n\n\n\n","preview":"Hi there! The press page is coming soon. In the mean time drop us a line and we'll get back to you. Press Kit Coming soon! Contact Details Email: contact@metricpanda.com...","categories":""},{"id":54,"type":"page","title":"Rival Fortress","url":"/rival-fortress/index.html","game":"rival-fortress","gameName":"Rival Fortress","content":"\n  \n    Rival Fortress is an upcoming \n    \n    exploration sandbox game set in an alien and hostile world.\n    \n    \n  \n  Keep an eye on this page for development updates, gameplay screenshots and videos.\n\n  \n    Screenshots and Videos\n  \n  Coming soon!\n\n  \n\n\n\n\n\n  \n    \n      Metric Panda Digest (sent monthly and \n          looks like this)\n      \n        \n        \n        \n          \n            Submit\n          \n        \n      \n      We hate spam as much as you do!\n    \n  \n\n\n\n\n","preview":"Rival Fortress is an upcoming exploration sandbox game set in an alien and hostile world. Keep an eye on this page for development updates, gameplay screenshots and videos. Screenshots and...","categories":""}]