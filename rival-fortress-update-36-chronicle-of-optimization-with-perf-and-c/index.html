<!DOCTYPE html><html class=no-js><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Chronicle of Optimization with perf and C | Metric Panda Games</title><meta name=description content="Note: You can find the source code for the optimized version of poly2tri on Github.I needed a fast and robust mesh triangulation solution for Metric Panda Engine and after some ..."><meta name=keywords><meta property=og:title content="Chronicle of Optimization with perf and C | Metric Panda Games"><meta property=og:type content=website><meta property=og:locale content=en_US><meta property=og:url content="https://metricpanda.com/rival-fortress-update-36-chronicle-of-optimization-with-perf-and-c/"><meta property=og:image content=https://metricpanda.comoptimize-poly2tri-0.png><meta name=twitter:title content="Chronicle of Optimization with perf and C"><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=@MetricPandaGame><meta name=twitter:creator content=@Unspongeful><meta name=twitter:description content="Note: You can find the source code for the optimized version of poly2tri on Github.I needed a fast and robust mesh triangulation solution for Metric Panda Engine and after some ..."><meta name=twitter:url content="https://metricpanda.com/rival-fortress-update-36-chronicle-of-optimization-with-perf-and-c/"><meta name=twitter:url content="https://metricpanda.com/rival-fortress-update-36-chronicle-of-optimization-with-perf-and-c/"><meta name=twitter:image content=https://metricpanda.comoptimize-poly2tri-0.png><meta name=twitter:image:alt content="Chronicle of Optimization with perf and C"><link rel=canonical href="https://metricpanda.com/rival-fortress-update-36-chronicle-of-optimization-with-perf-and-c/"><link rel=alternate type=application/rss+xml title="Metric Panda Games" href=https://metricpanda.com/feed.xml><link rel=apple-touch-icon href=apple-icon-precomposed.png><link rel="shortcut icon" sizes="16x16 24x24 32x32 48x48 64x64" href=https://metricpanda.com/favicon.ico><link data-turbolinks-track=reload rel=stylesheet type=text/css href=/assets/metricpanda-39b1a813586a62f5ab272a1dc423ec22fa36f235ccc08b5ec4a21a2c11cc3fe9.css></head><body><header class="header clearfix"><nav class="navbar navbar-custom js-navbar navbar-fixed-top"><div class=container><h3 class=text-muted><a href="/" class=title-backlink><span class=logo-icon><i class="logo-state sprite sprite-small-logo"></i></span><span class=logo-name>MPG</span></a></h3><ul class=nav><li class="nav-link-important nav-link"><a class=nav-action href=/rival-fortress>rival fortress</a></li><li class=nav-separator><i class="icon icon-circle"></i></li><li class=nav-link><a class=nav-action href="/">news</a></li><li class=nav-link><a class=nav-action href=/press.html>press</a></li><li class=nav-link><a data-turbolinks=false class="nav-action js-search-button search-button" href="/">&nbsp;<i class="icon icon-search"></i></a></li></ul></div></nav><section class="masthead js-masthead"><div class=masthead-home><div class=metric-panda-logo><a href="/" class="sprite sprite-logo"></a></div><h1>Metric Panda Games</h1><h2>One pixel at a time.<i></i></h2></div><div class="home-nav clearfix"><ul class="nav nav-pills"><li class=nav-item><span class="nav-block nav-title">News:</span></li><li class=nav-item><a class="nav-block nav-link" href="/">Featured</a></li><li class=nav-item><a class="nav-block nav-link" href="/news/">All</a></li><li class=nav-item><a class="nav-block nav-link" href=/news/rival-fortress.html>Rival Fortress</a></li><li class=nav-item><a class="nav-block nav-link" href=/news/other.html>Other</a></li></ul></div><div><div class="js-masthead-rainbow masthead-rainbow"><i></i></div></div></section></header><section class="js-search-results search-results"><div class="container page-content"><form class="js-search-form search-form"><div class=input-group><input type=text class="form-control js-search-query" placeholder=Search...> <span class=input-group-btn><button class="btn btn-primary" type=submit>Search</button></span></div></form><div class="js-search-results-list search-results-list posts post-list"></div><div class="js-search-results-listing js-search-result-status search-result-status search-result-listing"><button type=button class="btn btn-success js-close-search">Close <i class="icon icon-cancel-1"></i></button></div><div class="js-search-results-loading js-search-result-status search-result-status search-result-loading"><button type=button class="btn btn-info js-close-search">Loading...</button></div><div class="js-search-results-empty js-search-result-status search-result-status search-result-empty"><button type=button class="btn btn-danger js-close-search">No results found <i class="icon icon-cancel-1"></i></button></div></div></section><section class="js-main-content main-content"><article class="page-width post-page container page-content"><header class=post-header><h1 class=post-title>Chronicle of Optimization with perf and C</h1><p class=game-update><a href=rival-fortress>Rival Fortress Update #36</a></p><p class=post-meta>by <em>Gianni Milanesi</em> <span class=dot>•</span> Category: <a href=/news/rival-fortress.html>Rival Fortress</a></p></header><div class=post-content><p class=note><b>Note</b>: You can find the source code for the optimized version of poly2tri on <a href=https://github.com/MetricPanda/fast-poly2tri>Github</a>.</p><p>I needed a fast and robust mesh triangulation solution for <strong>Metric Panda Engine</strong> and after some research I found the excellent <a href=https://github.com/jhasse/poly2tri>Poly2Tri</a> library, an implementation in C++ of the <a href="http://www.tandfonline.com/doi/abs/10.1080/13658810701492241?journalCode=tgis20">Sweep-line algorithm for constrained Delaunay triangulation</a>.</p><p>Metric Panda Engine is written in <em><a href=/rival-fortress-update-20-the-c-subset/index.html>C-style</a></em> C++, so I wanted to port the code for poly2tri and customize it to fit the engine’s needs.</p><p>While I ported the code I noticed opportunities for optimization, and in this post I’ll talk about what I did.</p><div class=post-media></div><h2 id=preparing-the-library-for-profiling>Preparing the library for profiling</h2><p>Before I went ahead and made changes I wanted a baseline profile measurement.</p><p>Fortunately Poly2tri comes with a <a href=https://github.com/jhasse/poly2tri/tree/master/testbed>testbed</a> with sample data that can be used to test the output of the library. The test application accepts a data file containing a list of point as input, runs the triangulation routine and displays the result using OpenGL.</p><p>The part I was interested in optimizing was the triangulation routine, so everything else that the test application did was noise that I had to minimize in order to get better readings while profiling.</p><p>To do so I modified the <code class=highlighter-rouge>main.cc</code> and did the following:</p><ul><li>Removed the OpenGL visualization part</li><li>Isolated all library related function calls and placed them in a loop to reduce the noise from the startup of the testbed application</li></ul><p>The relevant part of the refactored testbed looks like this:</p><figure class=highlight><pre><code class=language-cpp data-lang=cpp>  <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>Iteration</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>Iteration</span> <span class=o>&lt;</span> <span class=n>MAX_ITERATIONS</span><span class=p>;</span> <span class=o>++</span><span class=n>Iteration</span><span class=p>)</span>
  <span class=p>{</span>
    <span class=n>CDT</span> <span class=n>cdt</span> <span class=o>=</span> <span class=n>CDT</span><span class=p>(</span><span class=n>polyline</span><span class=p>);</span>
    <span class=n>cdt</span><span class=p>.</span><span class=n>Triangulate</span><span class=p>();</span>
    <span class=n>ClearIteration</span><span class=p>(</span><span class=n>polyline</span><span class=p>);</span>
  <span class=p>}</span></code></pre></figure><p><strong>Note</strong>: The snippet above contained a call to <code class=highlighter-rouge>new</code> and <code class=highlighter-rouge>delete</code> in the initial version of the post. Creating the CDT on the stack saves the call to <code class=highlighter-rouge>malloc</code> and shaves off a little time from the benchmarked times.</p><h2 id=birds-eye-view-with-perf-stat>Bird’s eye view with <code class=highlighter-rouge>perf stat</code></h2><p>With Poly2tri ready to be profiled I jumped to my trusty <a href=https://perf.wiki.kernel.org/index.php/Main_Page>perf</a>, <em>the</em> profiling swiss army knife every Linux dev should have in their toolbox. On Windows, the best solution in probably Intel’s <a href=https://software.intel.com/en-us/intel-vtune-amplifier-xe>VTune</a>, but I don’t have any experience with it.</p><p>The first <code class=highlighter-rouge>perf</code> subcommand I always start with is <a href=https://perf.wiki.kernel.org/index.php/Tutorial#Counting_with_perf_stat>stat</a>:</p><p><code class=highlighter-rouge>taskset 2 perf stat --detailed --repeat 10 ./main testbed/data/debug2.dat 0 0 1</code></p><p>Several things are happening in this one-liner:</p><ul><li><p>The <code class=highlighter-rouge>taskset 2</code> will force the perf execution to happen on the second CPU core and avoid any random core migration that may muddy up the results. This can be safely done when dealing with single-threaded code, like it’s the case for Poly2tri.</p></li><li>The <code class=highlighter-rouge>perf stat</code> command runs the Poly2tri executable (<code class=highlighter-rouge>./main</code>) passing it <code class=highlighter-rouge>debug2.dat</code>, a test data file containing 10000 points to triangulate.</li><li>The <code class=highlighter-rouge>--detailed</code> flag will cause perf to output more counters.</li><li>The <code class=highlighter-rouge>--repeat 10</code> flag reruns the executable ten times and averages the results as well as printing the standard deviation between each run.</li><li>The <code class=highlighter-rouge>0 0 1</code> at the end are arguments that Poly2tri needs for the OpenGL visualization, but are not used in the modified testbed.</li></ul><p>This is the result with the interesting parts highlighted:</p><div class=post-media></div><ul><li><p>The first highlighted row shows the <strong>execution time in milliseconds</strong>. The rightmost column is the standard deviation between runs. A low standard deviation means the program is stable across runs.</p></li><li><p>The second highlighted row shows the <strong>instructions per cycle</strong>, an important metric that can give you hints on whether the CPU is stalling during execution.</p><p>The <a href=http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf>Intel® 64 and IA-32 Architectures Optimization Reference Manual</a> defines this metric as <strong>Clocks per Instructions Retired Ratio</strong> (CPI), and uses the inverse of what <code class=highlighter-rouge>perf</code> shows. The theoretical best on modern superscalar CPUs executing at full speed is 4 instructions per cycle. In the case of Poly2tri, 1.29 instructions per cycle indicate possible front-end or back-end stalls. A deeper analysis is required. Take a look at <a href=https://software.intel.com/en-us/top-down-microarchitecture-analysis-method-win>Tuning Applications Using a Top-down Microarchitecture Analysis Method</a> for more on the subject.</p></li><li><p>The third highlighted row shows the number of <a href=https://en.wikipedia.org/wiki/CPU_cache#Cache_miss>L1 cache misses</a>. Perf highlighted the percentage in yellow to indicate that this may be a potential hotspot and should be investigated further.</p></li></ul><h2 id=finding-the-hot-spots-with-perf-report>Finding the hot spots with <code class=highlighter-rouge>perf report</code></h2><p>Now that I had a baseline to work with, I used the next <code class=highlighter-rouge>perf</code> subcommand: <a href=https://perf.wiki.kernel.org/index.php/Tutorial#Sampling_with_perf_record>record</a>.</p><p><code class=highlighter-rouge>taskset 2 perf record -e cpu-clock,L1-dcache-load-misses ./main testbed/data/debug2.dat 0 0 1</code></p><p>The previous command will sample the execution of the program and read the event counters specified by the <code class=highlighter-rouge>-e</code> flag:</p><ul><li><code class=highlighter-rouge>cpu-clock</code>: measures the time spent in a function. This is useful for gauging the amount the functions we should be focusing on.</li><li><code class=highlighter-rouge>L1-dcache-load-misses</code>: will show the functions that triggered the most L1 cache misses</li></ul><p>The recorded data can be viewed with <code class=highlighter-rouge>perf report</code> and looks like this:</p><div class=post-media></div><p>The first set represents the top 5 functions sorted by <code class=highlighter-rouge>cpu-clock</code> with the percentage column on the left that indicates the amount of time spent overall. The second set of functions represent where L1 cache misses happened.</p><p>The functions of interest that appear in both sets are:</p><ul><li><code class=highlighter-rouge>p2t::Triangle::MarkNeighbor</code>: (<a href=https://github.com/jhasse/poly2tri/blob/d84fb6f6d5558aea2645a67d370d1ad4735b4003/poly2tri/common/shapes.cc#L59-L71>see on Github</a>) marks a triangle as a neighbor if they share two points along an edge.</li><li><code class=highlighter-rouge>__ieee754_atan2_avx</code>: (<a href=https://github.com/jhasse/poly2tri/blob/f52c0c1c0dd2d3722b3dfa2c7f722c4eac32087e/poly2tri/sweep/sweep.cc#L285-L303>see on Github</a>) is the <code class=highlighter-rouge>libm</code> implementation of the <a href=https://en.wikipedia.org/wiki/Atan2>atan2</a> function.</li><li><code class=highlighter-rouge>p2t::AdvancingFront::LocateNode</code>: (<a href=https://github.com/jhasse/poly2tri/blob/d84fb6f6d5558aea2645a67d370d1ad4735b4003/poly2tri/sweep/advancing_front.cc#L42-L62>see on Github</a>) traverses the doubly-linked-list of the <em>advancing front</em> looking for the next node to process.</li></ul><h2 id=digging-deeper-with-perf-annotate>Digging deeper with <code class=highlighter-rouge>perf annotate</code></h2><p>Now that we have a few hot spots to look at, we can fire up another perf subcommand: <a href=https://perf.wiki.kernel.org/index.php/Tutorial#Source_level_analysis_with_perf_annotate>annotate</a>.</p><p>Actually, instead of calling annotate directly, I find it easier to jump to it from <code class=highlighter-rouge>perf report</code> by selecting the function of interest and pressing <code class=highlighter-rouge>a</code>.</p><p>Cycling through the hottest instructions in the report for <code class=highlighter-rouge>cpu-clock</code> of <code class=highlighter-rouge>p2t::Triangle::MarkNeighbor</code> (by pressing <code class=highlighter-rouge>TAB</code>), most of hot spots are caused by this:</p><div class=post-media></div><p>It corresponds to the function <code class=highlighter-rouge>p2t::Triangle::Contains</code> (<a href=https://github.com/jhasse/poly2tri/blob/d84fb6f6d5558aea2645a67d370d1ad4735b4003/poly2tri/common/shapes.h#L296-L299>see on Github</a>) that is inlined by the optimizer.</p><p>The reason the <code class=highlighter-rouge>cmp %rcx,%rdx</code> takes up so many cycles is probably because of a CPU stall caused by either a cache miss or another dependent instruction.</p><p>Looking the report for <code class=highlighter-rouge>L1-dcache-load-misses</code> seems to confirm the suspicion:</p><div class=post-media></div><p>The other function on the hot spot list, <code class=highlighter-rouge>p2t::AdvancingFront::LocateNode</code>, also suffers from a similar issue: the CPU is having to wait for memory access because of heavy usage of <a href=https://en.wikipedia.org/wiki/Doubly_linked_list>doubly linked lists</a>.</p><p>Ways to optimize these sorts of CPU stalls involve improving the cache locality of the data (i.e. keep the data that needs to be worked on closer together in memory). This can’t always be done directly if the underlying algorithm has certain constraints, but often times there is a better way.</p><p>An excellent video on the subject is <a href=https://twitter.com/mike_acton>Mike Acton’s</a> great <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">Data-Oriented Design and C++</a> talk.</p><h2 id=time-to-optimize>Time to Optimize</h2><p>Before I went about focusing on optimizing cache locality, I wanted to go for the low hanging fruits.</p><h3 id=bye-bye-new-and-push_back>Bye bye <code class=highlighter-rouge>new</code> and <code class=highlighter-rouge>push_back</code></h3><p>For the first optimization pass I decided to remove all dynamic allocations caused by calls to <code class=highlighter-rouge>std::vector.push_back</code> and <code class=highlighter-rouge>new</code>. I never use dynamic allocation in performance critical code, and instead use <a href=/rival-fortress-update-16-custom-memory-allocators/index.html>many types of custom allocators</a> depending on the needs.</p><p>I replaced these allocations with a simple fixed-size <em>push allocator</em> that partitions a large memory block that is passed in to the library during initialization. The push allocator looks something like this:</p><figure class=highlight><pre><code class=language-cpp data-lang=cpp><span class=kt>void</span><span class=o>*</span> <span class=nf>Push</span><span class=p>(</span><span class=n>PolyPushAllocator</span><span class=o>*</span> <span class=n>Allocator</span><span class=p>,</span> <span class=kt>size_t</span> <span class=n>Size</span><span class=p>,</span> <span class=kt>size_t</span> <span class=n>AlignmentInBytes</span><span class=p>)</span>
<span class=p>{</span>
  <span class=kt>void</span><span class=o>*</span> <span class=n>Result</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
  <span class=kt>size_t</span> <span class=n>AlignmentOffset</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
  <span class=kt>size_t</span> <span class=n>MemoryAddress</span> <span class=o>=</span> <span class=p>(</span><span class=kt>size_t</span><span class=p>)</span><span class=n>Allocator</span><span class=o>-&gt;</span><span class=n>Memory</span><span class=p>;</span>
  <span class=k>if</span><span class=p>(</span><span class=n>MemoryAddress</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>AlignmentInBytes</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span>
  <span class=p>{</span>
    <span class=n>AlignmentOffset</span> <span class=o>=</span> <span class=n>AlignmentInBytes</span> <span class=o>-</span> <span class=p>(</span><span class=n>MemoryAddress</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>AlignmentInBytes</span><span class=o>-</span><span class=mi>1</span><span class=p>));</span>
  <span class=p>}</span>
  <span class=n>Size</span> <span class=o>+=</span> <span class=n>AlignmentOffset</span><span class=p>;</span>
  <span class=k>if</span> <span class=p>(</span><span class=n>Allocator</span><span class=o>-&gt;</span><span class=n>Used</span> <span class=o>+</span> <span class=n>Size</span> <span class=o>&lt;=</span> <span class=n>Allocator</span><span class=o>-&gt;</span><span class=n>Size</span><span class=p>)</span>
  <span class=p>{</span>
    <span class=n>Result</span> <span class=o>=</span> <span class=n>Allocator</span><span class=o>-&gt;</span><span class=n>Memory</span> <span class=o>+</span> <span class=p>(</span><span class=n>Allocator</span><span class=o>-&gt;</span><span class=n>Used</span> <span class=o>+</span> <span class=n>AlignmentOffset</span><span class=p>);</span>
    <span class=n>Allocator</span><span class=o>-&gt;</span><span class=n>Used</span> <span class=o>+=</span> <span class=n>Size</span><span class=p>;</span>
  <span class=p>}</span>
  <span class=k>return</span> <span class=n>Result</span><span class=p>;</span>
<span class=p>}</span></code></pre></figure><p>As you can see, it’s very simple and is lightning fast compared to <code class=highlighter-rouge>malloc</code>/<code class=highlighter-rouge>new</code>.</p><p>This optimization resulted in a ~39% performance increase from the baseline on the <code class=highlighter-rouge>debug2.dat</code> file and is proportional to the number of points the library has to process: the more points in the data set there are, the slower dynamic allocations will become.</p><div class=post-media></div><h3 id=doubles-to-floats>Doubles to floats</h3><p>The next optimization I had on my checklist was changing the type for floating point from <code class=highlighter-rouge>double</code> to <code class=highlighter-rouge>float</code>.</p><p>My assumption was that since the precision of 64bit floating point numbers was not needed for this type of library, why not use <code class=highlighter-rouge>floats</code> and allow the CPU potentially increase bandwidth and parallelization.</p><p>The result was a tiny improvement in performance, mostly because the algorithm doesn’t do any wide operations of floating point numbers that would benefit from the increased bandwidth.</p><div class=post-media></div><h3 id=faster-atan2-function>Faster Atan2 function</h3><p>As seen above, the <a href=https://en.wikipedia.org/wiki/Atan2>atan2</a> is one of the hot spots of Poly2tri, so I tried to replace it with an approximate version of the function with a <em>good enough</em> error.</p><p>The implementation I ended up with is based on <a href=https://gist.github.com/volkansalma/2972237>this fast atan2 approximation</a> and has a maximum error of 0.005 radians. That is perfectly acceptable for my needs.</p><div class=post-media></div><h3 id=optimizing-cache-misses>Optimizing Cache Misses</h3><p>The last item on my list was cache misses.</p><p>While working on the previous optimizations I gained a better understanding on the algorithm Poly2tri is aimed at implementing. The heavy usage of linked lists and double pointers was a sensible decision by the original implementer, and honestly I can’t really thing of a more performant way of doing things.</p><p>In the end I tried my best to reduce cache pressure with micro optimizations here and there. The final result is acceptable, but code in some sections may have become more cryptic for people trying to understand the algorithm.</p><p>This is what I did:</p><ul><li>Replaced the <code class=highlighter-rouge>std::vector</code> to the Edges in <code class=highlighter-rouge>pt2::Point</code> to a linked list. The edges initialized are once and not accessed often, so this change allowed for easier memory management.</li><li>Replaced the <code class=highlighter-rouge>bool</code> arrays on <code class=highlighter-rouge>pt2::Triangle</code> (<a href=https://github.com/jhasse/poly2tri/blob/d84fb6f6d5558aea2645a67d370d1ad4735b4003/poly2tri/common/shapes.h#L156-L159>see on Github</a>) with an unsigned int field that is used as a bit mask. The advantage is that bit operations are very cheap and avoid may of the branches used in the original implementation.</li><li>Removed many of the branches that caused cache misses like the one showcased earlier.</li><li>Used a global lookup table for faster access of triangle array indices when rotating left or right from a point.</li></ul><p>The final, optimized, result on the <code class=highlighter-rouge>debug2.dat</code> sample data with 100 iterations resulted in ~100% speed increase:</p><div class=post-media></div><aside class="share readable"><span>Share this:</span> <a href="http://twitter.com/share?text=Rival Fortress Update #36: Chronicle of Optimization with perf and C&amp;url=https://metricpanda.com/rival-fortress-update-36-chronicle-of-optimization-with-perf-and-c/index.html" class=js-analytics data-target=twitter-share onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;"><i class="icon icon-twitter"></i></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://metricpanda.com/rival-fortress-update-36-chronicle-of-optimization-with-perf-and-c/index.html" class=js-analytics data-target=facebook-share onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;"><i class="icon icon-facebook"></i></a></aside></div><hr class=hr><div class="page-width newsletter-form"><form action=https://tinyletter.com/metricpanda class=js-analytics-form data-target=newsletter-submit method=post target=popupwindow onsubmit="window.open('https://tinyletter.com/metricpanda', 'popupwindow', 'scrollbars=yes,width=800,height=600');return true"><label for=tlemail><b>Metric Panda Digest</b> <em>(sent monthly and <a data-turbolinks=false class=js-analytics data-target=newsletter-preview href=/newsletters/newsletter-2016-september.html>looks like this</a>)</em></label><div class=input-group><input type=email name=email class=form-control id=tlemail placeholder="Enter your email" required> <input type=hidden value=1 name=embed> <span class=input-group-btn><button class="btn btn-primary" type=submit>Submit</button></span></div><small class=text-muted>We hate spam as much as you do!</small></form></div><hr class=hr></article></section><footer class="site-footer clearfix"><ul class="social js-social"><li><a href=https://github.com/MetricPanda class=js-analytics data-target=github-metricpanda-footer target=_blank><i class="icon icon-github-circled"></i> <b>Github</b></a></li></ul><small>&copy; 2019 Metric Panda Games All rights reserved. <i class="icon icon-star-empty" title=d32745f></i></small><div class=footer-logo><i class="icon icon-metric-panda"></i></div></footer><script data-turbolinks-track=reload data-turbolinks-eval=false type=text/javascript src=/assets/metricpanda-642bfda95fce5f4276f3ac16fa8c8ff98d1d3ef275ab201acce574d9b5d1888f.js></script></body></html>